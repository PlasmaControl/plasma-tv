{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversion Intensity\n",
    "\n",
    "Tracks left/right radiation points and X-point, including brightness (intensity) for D-IIID TV images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import readsav\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.animation as animation\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(filename):\n",
    "    dat = readsav(filename)\n",
    "    emission = dat['emission_structure']\n",
    "    return emission[0]\n",
    "\n",
    "def _find_index(arr,val):\n",
    "    return np.argmin(abs(arr-val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('tv_images/l-mode')\n",
    "filename = 'emission_structure_pu_cam240perp_190113'\n",
    "fullfile = filename + '.sav'\n",
    "[inverted,radii,elevation,frames,times,vid_frames,vid_times,vid] = _load_data(filepath / fullfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Image With Corner Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverted: R,Z Coordinate Array\n",
    "Radii/Elevation are redundant across times. Can just use ones from t=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fid = 50\n",
    "tid = _find_index(vid_times,times[fid]) #find frame id for camera image with t=times[fid]\n",
    "find_x = inverted[fid]\n",
    "img = inverted[fid].copy()\n",
    "gray=(255-255*(img-np.min(img))/(np.max(img)-np.min(img))).astype('uint8')\n",
    "useHarrisDetector = False # False uses Shi-Tomasi Corner Detector\n",
    "corners = np.intp(cv2.goodFeaturesToTrack(gray,3,.5,10, useHarrisDetector=useHarrisDetector))\n",
    "x = radii[0][corners[:,0,0]]\n",
    "y = elevation[0][corners[:,0,1]]\n",
    "print(np.column_stack((x,y)))\n",
    "plt.pcolormesh(radii[fid],elevation[fid],img,shading='auto', cmap='gray')\n",
    "plt.scatter(x,y,color='red')\n",
    "plt.title(f\"Inverted with Radiation Points, Frame {fid}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Point Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_value(array):\n",
    "    return np.sqrt(np.mean(np.square(array)))\n",
    "\n",
    "# converts from natural units to indices\n",
    "def convert_center(radii, elevation, value):\n",
    "    rad_idx = (np.abs(radii - value[0])).argmin()\n",
    "    elev_idx = (np.abs(elevation - value[1])).argmin()\n",
    "    return rad_idx, elev_idx\n",
    "\n",
    "# distance from test point to line created by point_1 and point_2\n",
    "def get_dist_line(point_1, point_2, test_point):\n",
    "    top = np.abs(point_2[0]-point_1[0])*(point_2[1]-test_point[1])-(point_1[0]-test_point[0])*(point_2[1]-point_1[1])\n",
    "    bottom = np.sqrt((point_2[0]-point_1[0])**2+(point_2[1]-point_1[1])**2)\n",
    "    return top / bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundary array for frame around center point\n",
    "def get_bounds(centers, dist, im_size):\n",
    "    \n",
    "    bounds = np.array([centers - dist, centers + dist])\n",
    "    \n",
    "    bounds[bounds < 0] = 0 # set negative bounds to 0\n",
    "    \n",
    "    new_vals = bounds.copy()\n",
    "    new_vals[new_vals > im_size[0]] = im_size[0]\n",
    "    bounds[:,:,0] = new_vals[:,:,0] # set x bounds within x frame\n",
    "    \n",
    "    new_vals = bounds.copy()\n",
    "    new_vals[new_vals > im_size[1]] = im_size[1]\n",
    "    bounds[:,:,1] = new_vals[:,:,1] # set y bounds within y frame\n",
    "    \n",
    "    return bounds\n",
    "\n",
    "# array of corners using Shi-Tomasi Corner Detector\n",
    "def get_corners(img):\n",
    "    \n",
    "    gray = (255-255*(img-np.min(img))/(np.max(img)-np.min(img))).astype('uint8')\n",
    "    corners = np.intp(cv2.goodFeaturesToTrack(gray,3,.05,5, useHarrisDetector=False))\n",
    "    x = corners[:,0,0]\n",
    "    y = corners[:,0,1]\n",
    "    \n",
    "    return np.column_stack((x,y))\n",
    "\n",
    "# array of corner pixel frame intensities\n",
    "def get_corner_values(img, corners, dist, im_size):\n",
    "    \n",
    "    bounds = get_bounds(corners, dist, im_size)\n",
    "    \n",
    "    avg_values = []\n",
    "    \n",
    "    for i in range(len(corners)):\n",
    "        temp_frame = img[bounds[0,i,1]:bounds[1,i,1],bounds[0,i,0]:bounds[1,i,0]]\n",
    "        avg_values.append(get_avg_value(temp_frame))\n",
    "    \n",
    "    return avg_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding and merging the most likely radiation points\n",
    "1. X-point is absolute\n",
    "1. Merge radiation points that are close together\n",
    "1. Provided that there also exists a corner that is close enough to the previous line formed by the x-point and radiation point, then replace radiation point with corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges points that are close together and sets new radiation points to possible corners if they meet threshold criteria\n",
    "def merge_points(centers_old, centers_new, corners, avg_values, avg_values_corners, merge_threshold, distance_threshold):\n",
    "    \n",
    "    right_dist = []\n",
    "    left_dist = []\n",
    "    centers_new_update = centers_new.copy()\n",
    "    avg_values_update = avg_values.copy()\n",
    "    \n",
    "    for i in range(len(corners)):\n",
    "        right_dist.append(get_dist_line(centers_old[0],centers_old[1],corners[i]))\n",
    "        left_dist.append(get_dist_line(centers_old[0],centers_old[2],corners[i]))\n",
    "\n",
    "    l_x_dist = np.sqrt(np.sum(np.square(centers_new[0]-centers_new[1])))\n",
    "    r_x_dist = np.sqrt(np.sum(np.square(centers_new[0]-centers_new[2])))\n",
    "    \n",
    "    if (l_x_dist < merge_threshold) and (np.min(left_dist)) < distance_threshold:\n",
    "        index = np.where(right_dist == np.min(left_dist))[0][0]\n",
    "        centers_new_update[1] = corners[index]\n",
    "        avg_values_update[1] = avg_values_corners[index]\n",
    "    \n",
    "    if (r_x_dist < merge_threshold) and (np.min(right_dist) < distance_threshold):\n",
    "        index = np.where(right_dist == np.min(right_dist))[0][0]\n",
    "        centers_new_update[2] = corners[index]\n",
    "        avg_values_update[2] = avg_values_corners[index]\n",
    "    \n",
    "    return centers_new_update, avg_values_update\n",
    "\n",
    "# array of values for x point and 2 radiation points\n",
    "def get_center_values(img, centers, dist, im_size, merge_threshold, distance_threshold):\n",
    "    \n",
    "    bounds = get_bounds(centers, dist, im_size)\n",
    "    \n",
    "    x_frame = img[bounds[0,0,1]:bounds[1,0,1],bounds[0,0,0]:bounds[1,0,0]]\n",
    "    l_frame = img[bounds[0,1,1]:bounds[1,1,1],bounds[0,1,0]:bounds[1,1,0]]\n",
    "    r_frame = img[bounds[0,2,1]:bounds[1,2,1],bounds[0,2,0]:bounds[1,2,0]]\n",
    "    \n",
    "    local_x_max = np.unravel_index(np.argmax(x_frame), x_frame.shape)\n",
    "    local_l_max = np.unravel_index(np.argmax(l_frame), l_frame.shape)\n",
    "    local_r_max = np.unravel_index(np.argmax(r_frame), r_frame.shape)\n",
    "    \n",
    "    global_x_max = np.flip(np.ravel(local_x_max)) + [bounds[0,0,0], bounds[0,0,1]]\n",
    "    global_l_max = np.flip(np.ravel(local_l_max)) + [bounds[0,1,0], bounds[0,1,1]]\n",
    "    global_r_max = np.flip(np.ravel(local_r_max)) + [bounds[0,2,0], bounds[0,2,1]]\n",
    "    \n",
    "    centers_update = np.array([global_x_max, global_l_max, global_r_max])\n",
    "    avg_values = np.array([get_avg_value(x_frame), get_avg_value(l_frame), get_avg_value(r_frame)])\n",
    "    \n",
    "    corners = get_corners(img)\n",
    "    avg_values_corners = get_corner_values(img, corners, dist, im_size)\n",
    "    new_centers, new_avg_vals = merge_points(centers, centers_update, corners, avg_values, avg_values_corners, merge_threshold, distance_threshold)\n",
    "        \n",
    "    return new_centers, new_avg_vals\n",
    "\n",
    "# update frame with new centers if avg value is greater than threshold\n",
    "def update_frame(img, centers, dist, im_size, intensity_threshold, merge_threshold, distance_threshold):\n",
    "    \n",
    "    new_centers, new_avg_vals = get_center_values(img, centers, dist, im_size, merge_threshold, distance_threshold)\n",
    "    \n",
    "    for i in range(3):\n",
    "        if new_avg_vals[i] > intensity_threshold:\n",
    "            centers[i] = new_centers[i]\n",
    "    \n",
    "    return centers, new_avg_vals\n",
    "\n",
    "# main function\n",
    "def main(input_array, centers_ini, dist, im_size, intensity_threshold, merge_threshold, distance_threshold, num_iter):\n",
    "    centers = centers_ini.copy()\n",
    "    centers_array = []\n",
    "    avg_values_array = []\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        img = input_array[i].copy()\n",
    "        centers_update, avg_values_temp = update_frame(img, centers, dist, im_size, intensity_threshold, merge_threshold, distance_threshold)\n",
    "        centers_array.append(centers_update)\n",
    "        avg_values_array.append(avg_values_temp)\n",
    "        centers = centers_update.copy()\n",
    "    \n",
    "    return np.array(centers_array), np.array(avg_values_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize values\n",
    "x_0 = np.array([1.33,-1.05]) # x-point location\n",
    "l_0 = np.array([1.1,-1.3]) # left radiation point location\n",
    "r_0 = np.array([1.42,-1.15]) # right radiation point location\n",
    "\n",
    "centers_0 = np.array([convert_center(radii,elevation,x_0),\n",
    "                      convert_center(radii,elevation,l_0),\n",
    "                      convert_center(radii,elevation,r_0)])\n",
    "\n",
    "x, y = zip(*centers_0)\n",
    "img = inverted[0].copy()\n",
    "plt.pcolormesh(radii[0],elevation[0],img,shading='auto', cmap='viridis')\n",
    "plt.scatter(radii[0,x],elevation[0,y],s=5,c='tab:orange',label='intensity')\n",
    "plt.xticks(np.arange(min(radii[0]), max(radii[0]), 0.1))\n",
    "plt.yticks(np.arange(min(elevation[0]), max(elevation[0]), 0.1))\n",
    "plt.show()\n",
    "\n",
    "radius = 10 # for some reason, 6 just works the best while every other value doesn't work\n",
    "threshold = 0.1 # intensity value threshold for points to update their position\n",
    "merge_threshold = 1 # merge threshold for radiation point and X-point, should be on factor of 2X radius\n",
    "distance_threshold = 1 # distance from emission line for corner to be considered a radiation point\n",
    "\n",
    "# run main function\n",
    "centers_array, avg_values_array = main(inverted, centers_0, radius, img.shape, threshold, merge_threshold, distance_threshold, len(inverted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pixel location to natural units\n",
    "r_natural = radii[0][centers_array[:,:,0]]\n",
    "e_natural = elevation[0][centers_array[:,:,1]]\n",
    "centers_array_natural = np.dstack((r_natural,e_natural))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_values_array)\n",
    "plt.legend(['x','l','r'])\n",
    "plt.title(filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Circle bounds around point is a bit misleading, it's actually a square. But differences shouldn't be too big.\n",
    "\n",
    "Intensity is the tracked points. Corners is any corners that gets noticed by detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample plot of calculated centers\n",
    "idx = 90\n",
    "x, y = zip(*centers_array[idx])\n",
    "img = inverted[idx].copy()\n",
    "\n",
    "scaling = radii[0,1]-radii[0,0]\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "circ_0 = plt.Circle((radii[0,x[0]], elevation[0,y[0]]), scaling*radius, color='tab:red', fill=False)\n",
    "circ_1 = plt.Circle((radii[0,x[1]], elevation[0,y[1]]), scaling*radius, color='tab:red', fill=False)\n",
    "circ_2 = plt.Circle((radii[0,x[2]], elevation[0,y[2]]), scaling*radius, color='tab:red', fill=False)\n",
    "line1x = [radii[0,x[0]],radii[0,x[1]]]\n",
    "line1y = [elevation[0,y[0]],elevation[0,y[1]]]\n",
    "line2x = [radii[0,x[0]],radii[0,x[2]]]\n",
    "line2y = [elevation[0,y[0]],elevation[0,y[2]]]\n",
    "\n",
    "axs.pcolormesh(radii[0],elevation[0],img,shading='auto', cmap='plasma')\n",
    "axs.plot(line1x,line1y,color='tab:blue')\n",
    "axs.plot(line2x,line2y,color='tab:blue')\n",
    "axs.scatter(radii[0,x],elevation[0,y],s=5,c='tab:orange',label='intensity')\n",
    "axs.add_artist(circ_0)\n",
    "axs.add_artist(circ_1)\n",
    "axs.add_artist(circ_2)\n",
    "\n",
    "gray=(255-255*(img-np.min(img))/(np.max(img)-np.min(img))).astype('uint8')\n",
    "corners = np.intp(cv2.goodFeaturesToTrack(gray,3,.5,10, useHarrisDetector=useHarrisDetector))\n",
    "x1 = radii[idx][corners[:,0,0]]\n",
    "y1 = elevation[idx][corners[:,0,1]]\n",
    "axs.scatter(x1,y1,color='cyan',s=5,marker='x',label='corners')\n",
    "plt.suptitle(filename)\n",
    "plt.title(f'Time = {times[idx]-times[0]:.2f} ms')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate video\n",
    "savepath = Path('outputs/inversion_videos') / f'{filename}.gif'\n",
    "fig, axs = plt.subplots()\n",
    "\n",
    "def animate(idx):\n",
    "    x, y = zip(*centers_array[idx])\n",
    "    img = inverted[idx].copy()\n",
    "\n",
    "    circ_0 = plt.Circle((radii[0,x[0]], elevation[0,y[0]]), scaling*radius, color='tab:red', fill=False)\n",
    "    circ_1 = plt.Circle((radii[0,x[1]], elevation[0,y[1]]), scaling*radius, color='tab:red', fill=False)\n",
    "    circ_2 = plt.Circle((radii[0,x[2]], elevation[0,y[2]]), scaling*radius, color='tab:red', fill=False)\n",
    "    \n",
    "    line1x = [radii[0,x[0]],radii[0,x[1]]]\n",
    "    line1y = [elevation[0,y[0]],elevation[0,y[1]]]\n",
    "    line2x = [radii[0,x[0]],radii[0,x[2]]]\n",
    "    line2y = [elevation[0,y[0]],elevation[0,y[2]]]\n",
    "\n",
    "    axs.clear()\n",
    "    \n",
    "    axs.pcolormesh(radii[0],elevation[0],img,shading='auto', cmap='plasma')\n",
    "    axs.plot(line1x,line1y,color='tab:blue')\n",
    "    axs.plot(line2x,line2y,color='tab:blue')\n",
    "    axs.scatter(radii[0,x],elevation[0,y],s=5,c='tab:orange',label='intensity')\n",
    "    axs.add_artist(circ_0)\n",
    "    axs.add_artist(circ_1)\n",
    "    axs.add_artist(circ_2)\n",
    "    \n",
    "    plt.xlabel('Radius (m)')\n",
    "    plt.ylabel('Elevation (m)')\n",
    "    plt.suptitle(filename)\n",
    "    plt.title(f'Time = {times[idx]-times[0]:.2f} ms')\n",
    "\n",
    "writervideo = animation.FFMpegWriter(fps=15) \n",
    "ani = animation.FuncAnimation(fig, animate, frames=tqdm(range(len(centers_array))))\n",
    "ani.save(savepath, writer='Pillow', fps=15)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datpath = Path('outputs/inversion_data')\n",
    "dictionary = {'frame': frames,\n",
    "              'x_location': centers_array[:,0,:],\n",
    "              'l_location': centers_array[:,1,:],\n",
    "              'r_location': centers_array[:,2,:],\n",
    "              'x_intensity': avg_values_array[:,0],\n",
    "              'l_intensity': avg_values_array[:,1],\n",
    "              'r_intensity': avg_values_array[:,2]}\n",
    "    \n",
    "savepkl = (datpath / filename).with_suffix('.pkl')\n",
    "\n",
    "with open(savepkl, 'wb') as f:\n",
    "    pickle.dump(dictionary, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate Across All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = [f for f in filepath.glob('*') if f.is_file()]\n",
    "print(file_name[13:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('tv_images')\n",
    "datpath = Path('inversion_data')\n",
    "vidpath = Path('inversion_videos')\n",
    "\n",
    "file_name = [f for f in filepath.glob('*') if f.is_file()]\n",
    "[inverted,radii,elevation,frames,_,_,_,_] = _load_data(file_name[0])\n",
    "# initialize values\n",
    "x_0 = np.array([1.35,-1.05]) # x-point location\n",
    "l_0 = np.array([1.0,-1.25]) # left radiation point location\n",
    "r_0 = np.array([1.5,-1.25]) # right radiation point location\n",
    "\n",
    "centers_0 = np.array([convert_center(radii,elevation,x_0),\n",
    "                      convert_center(radii,elevation,l_0),\n",
    "                      convert_center(radii,elevation,r_0)])\n",
    "\n",
    "radius = 6 # for some reason, 6 just works the best while every other value doesn't work\n",
    "threshold = 0.05 # intensity value threshold for points to update their position\n",
    "merge_threshold = 20 # merge threshold for radiation point and X-point, should be on factor of 2X radius\n",
    "distance_threshold = 10 # distance from emission line for corner to be considered a radiation point\n",
    "\n",
    "for file in tqdm(file_name[14:]):\n",
    "    print(file.stem)\n",
    "    [inverted,radii,elevation,frames,times,_,_,_] = _load_data(file)\n",
    "    r = radii[0]\n",
    "    z = elevation[0]\n",
    "    centers_array, avg_values_array = main(inverted, centers_0, radius, inverted[0].shape, threshold, merge_threshold, distance_threshold, len(inverted))\n",
    "    centers_array_natural = np.dstack((radii[0][centers_array[:,:,0]],elevation[0][centers_array[:,:,1]]))\n",
    "    dictionary = {'frame': frames,\n",
    "              'x_location': centers_array_natural[:,0,:],\n",
    "              'l_location': centers_array_natural[:,1,:],\n",
    "              'r_location': centers_array_natural[:,2,:],\n",
    "              'x_intensity': avg_values_array[:,0],\n",
    "              'l_intensity': avg_values_array[:,1],\n",
    "              'r_intensity': avg_values_array[:,2]}\n",
    "    \n",
    "    savepkl = (datpath / file.stem).with_suffix('.pkl')\n",
    "    \n",
    "    with open(savepkl, 'wb') as f:\n",
    "        pickle.dump(dictionary, f)\n",
    "        \n",
    "    savevid = (vidpath / file.stem).with_suffix('.mp4')\n",
    "    \n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    def animate(idx):\n",
    "        x, y = zip(*centers_array[idx])\n",
    "        img = inverted[idx].copy()\n",
    "\n",
    "        circ_0 = plt.Circle((radii[0,x[0]], elevation[0,y[0]]), scaling*radius, color='tab:red', fill=False)\n",
    "        circ_1 = plt.Circle((radii[0,x[1]], elevation[0,y[1]]), scaling*radius, color='tab:red', fill=False)\n",
    "        circ_2 = plt.Circle((radii[0,x[2]], elevation[0,y[2]]), scaling*radius, color='tab:red', fill=False)\n",
    "        \n",
    "        line1x = [radii[0,x[0]],radii[0,x[1]]]\n",
    "        line1y = [elevation[0,y[0]],elevation[0,y[1]]]\n",
    "        line2x = [radii[0,x[0]],radii[0,x[2]]]\n",
    "        line2y = [elevation[0,y[0]],elevation[0,y[2]]]\n",
    "\n",
    "        axs.clear()\n",
    "        \n",
    "        axs.pcolormesh(radii[0],elevation[0],img,shading='auto', cmap='plasma')\n",
    "        axs.plot(line1x,line1y,color='tab:blue')\n",
    "        axs.plot(line2x,line2y,color='tab:blue')\n",
    "        axs.scatter(radii[0,x],elevation[0,y],s=5,c='tab:orange',label='intensity')\n",
    "        axs.add_artist(circ_0)\n",
    "        axs.add_artist(circ_1)\n",
    "        axs.add_artist(circ_2)\n",
    "        \n",
    "        plt.xlabel('Radius (m)')\n",
    "        plt.ylabel('Elevation (m)')\n",
    "        plt.suptitle(file.stem)\n",
    "        plt.title(f'Time = {times[idx]-times[0]:.2f} ms')\n",
    "\n",
    "    writervideo = animation.FFMpegWriter(fps=15) \n",
    "    ani = animation.FuncAnimation(fig, animate, frames=tqdm(range(len(centers_array)-1)))\n",
    "    ani.save(savevid, writer=writervideo)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-Supervised Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('tv_images')\n",
    "datpath = Path('inversion_data')\n",
    "modelpath = Path('models')\n",
    "\n",
    "file_name = 'lr_inversion_points.pkl'\n",
    "\n",
    "with open(modelpath / file_name, 'rb') as f:\n",
    "    inversion_model = pickle.load(f)\n",
    "\n",
    "file_name = [f for f in filepath.glob('*') if f.is_file()]\n",
    "file = file_name[0]\n",
    "inversion_vid = readsav(file)['emission_structure'][0][0]\n",
    "inversion_vid_copy = inversion_vid.copy()\n",
    "inversion_vid = (255-255*(inversion_vid-np.min(inversion_vid))/(np.max(inversion_vid)-np.min(inversion_vid)))/255\n",
    "inversion_vid = inversion_vid.reshape((len(inversion_vid), -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open((datpath / file_name[0].stem).with_suffix('.pkl'), 'rb') as f:\n",
    "    inversion_data = pickle.load(f)\n",
    "    \n",
    "l = inversion_data['l_location']\n",
    "r = inversion_data['r_location']\n",
    "points_arr = np.concatenate((l, r),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = inversion_model.predict(inversion_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = inversion_model.score(inversion_vid, points_arr)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create scatter plots\n",
    "bg_vid = ax.imshow(inversion_vid_copy[0], cmap='gray', origin='lower', extent=[1,2,-1.4,-.4])\n",
    "scat_pred = ax.scatter([], [], c='lime', label='predicted')\n",
    "scat_actual = ax.scatter([], [], c='red', label='actual')\n",
    "ax.set_xlim([1,2])\n",
    "ax.set_ylim([-1.4,-.4])\n",
    "ax.legend()\n",
    "ax.set_title(\"Emission Front Locations\")\n",
    "plt.tight_layout()\n",
    "\n",
    "def update(num):\n",
    "    x1, y1, x2, y2 = predict[num]\n",
    "    a1, b1, a2, b2 = points_arr[num]\n",
    "    bg_vid.set_data(inversion_vid_copy[num])\n",
    "    \n",
    "    scat_pred.set_offsets(np.c_[[x1, x2], [y1, y2]])\n",
    "    scat_actual.set_offsets(np.c_[[a1, a2], [b1, b2]])\n",
    "    return scat_pred, scat_actual, bg_vid\n",
    "\n",
    "FFwriter = animation.FFMpegWriter(fps=60)\n",
    "ani = animation.FuncAnimation(fig, update, frames=tqdm(range(len(predict))), interval=20, blit=True)\n",
    "ani.save(Path(f'./tmp/{file.stem}_regress2.mp4'), writer=FFwriter)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_index(arr,val):\n",
    "    return np.argmin(abs(arr-val))\n",
    "\n",
    "def get_index(radius_map, elevation_map, point_array):\n",
    "    rad_coord = list(map(_find_index, radius_map, point_array[0]))\n",
    "    ele_coord = list(map(_find_index, elevation_map, point_array[1]))\n",
    "    return np.array([rad_coord, ele_coord]).T\n",
    "\n",
    "rad_map = readsav(file)['emission_structure'][0][1]\n",
    "ele_map = readsav(file)['emission_structure'][0][2]\n",
    "l_point = predict.T[[0,1],:]\n",
    "r_point = predict.T[[2,3],:]\n",
    "l_point_coord = get_index(rad_map, ele_map, l_point)\n",
    "r_point_coord = get_index(rad_map, ele_map, r_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_size = 13\n",
    "l_frame = np.array([l_point_coord[:,0]-frame_size,l_point_coord[:,0]+frame_size,\n",
    "                    l_point_coord[:,1]-frame_size,l_point_coord[:,1]+frame_size]).T\n",
    "l_frame = np.where(l_frame < 0, 0, l_frame)\n",
    "l_frame = np.where(l_frame > 201, 201, l_frame)\n",
    "\n",
    "r_frame = np.array([r_point_coord[:,0]-frame_size,r_point_coord[:,0]+frame_size,\n",
    "                    r_point_coord[:,1]-frame_size,r_point_coord[:,1]+frame_size]).T\n",
    "r_frame = np.where(r_frame < 0, 0, r_frame)\n",
    "r_frame = np.where(r_frame > 201, 201, r_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_vid(vid, frame, idx):\n",
    "    return vid[idx][frame[idx,2]:frame[idx,3],frame[idx,0]:frame[idx,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_vid = [crop_vid(inversion_vid_copy, l_frame, i) for i in range(len(inversion_vid_copy))]\n",
    "max_loc = np.array([np.flip(np.unravel_index(np.argmax(cropped_vid[i]), cropped_vid[i].shape)) for i in range(len(cropped_vid))])\n",
    "true_max_loc_l = max_loc + l_frame[:,[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_vid = [crop_vid(inversion_vid_copy, r_frame, i) for i in range(len(inversion_vid_copy))]\n",
    "max_loc = np.array([np.flip(np.unravel_index(np.argmax(cropped_vid[i]), cropped_vid[i].shape)) for i in range(len(cropped_vid))])\n",
    "true_max_loc_r = max_loc + r_frame[:,[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cropped_vid[5], origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 120\n",
    "\n",
    "plt.imshow(inversion_vid_copy[idx], cmap = 'grey', origin = 'lower')\n",
    "plt.scatter(true_max_loc_l[idx][0], true_max_loc_l[idx][1], c='red', label = 'adjusted',s=5)\n",
    "plt.scatter(l_point_coord[idx][0], l_point_coord[idx][1], c='cyan', label = 'original',s=3)\n",
    "plt.scatter(true_max_loc_r[idx][0], true_max_loc_r[idx][1], c='red',s=5)\n",
    "plt.scatter(r_point_coord[idx][0], r_point_coord[idx][1], c='cyan',s=3)\n",
    "rect = patches.Rectangle((l_frame[idx,0],l_frame[idx,2]),l_frame[idx,1]-l_frame[idx,0],l_frame[idx,3]-l_frame[idx,2],linewidth=1,edgecolor='r',facecolor='none')\n",
    "rect2 = patches.Rectangle((r_frame[idx,0],r_frame[idx,2]),r_frame[idx,1]-r_frame[idx,0],r_frame[idx,3]-r_frame[idx,2],linewidth=1,edgecolor='r',facecolor='none')\n",
    "plt.gca().add_patch(rect)\n",
    "plt.gca().add_patch(rect2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create scatter plots\n",
    "bg_vid = ax.imshow(inversion_vid_copy[0], cmap='gray', origin='lower')\n",
    "scat_l = ax.scatter([], [], c='cyan', label='regression', s=10)\n",
    "scat_r = ax.scatter([], [], c='cyan', s=10)\n",
    "scat_l_adj = ax.scatter([], [], c='red', label='adjusted', s=5)\n",
    "scat_r_adj = ax.scatter([], [], c='red', s=5)\n",
    "rect_p = ax.add_patch(patches.Rectangle((l_frame[0,0],l_frame[0,2]),l_frame[0,1]-l_frame[0,0],l_frame[0,3]-l_frame[0,2],linewidth=1,edgecolor='r',facecolor='none'))\n",
    "rect2_p = ax.add_patch(patches.Rectangle((r_frame[0,0],r_frame[0,2]),r_frame[0,1]-r_frame[0,0],r_frame[0,3]-r_frame[0,2],linewidth=1,edgecolor='r',facecolor='none'))\n",
    "ax.legend()\n",
    "ax.set_title(\"Emission Front Locations\")\n",
    "plt.tight_layout()\n",
    "\n",
    "def update(num):\n",
    "    bg_vid.set_data(inversion_vid_copy[num])\n",
    "    scat_l.set_offsets(l_point_coord[num])\n",
    "    scat_r.set_offsets(r_point_coord[num])\n",
    "    scat_l_adj.set_offsets(true_max_loc_l[num])\n",
    "    scat_r_adj.set_offsets(true_max_loc_r[num])\n",
    "    rect = patches.Rectangle((l_frame[num,0],l_frame[num,2]),l_frame[num,1]-l_frame[num,0],l_frame[num,3]-l_frame[num,2],linewidth=1,edgecolor='r',facecolor='none')\n",
    "    rect2 = patches.Rectangle((r_frame[num,0],r_frame[num,2]),r_frame[num,1]-r_frame[num,0],r_frame[num,3]-r_frame[num,2],linewidth=1,edgecolor='r',facecolor='none')\n",
    "    rect_p.set_xy((l_frame[num,0],l_frame[num,2]))\n",
    "    rect2_p.set_xy((r_frame[num,0],r_frame[num,2]))\n",
    "    return bg_vid, scat_l, scat_r, scat_l_adj, scat_r_adj, rect_p, rect2_p\n",
    "\n",
    "FFwriter = animation.FFMpegWriter(fps=30)\n",
    "ani = animation.FuncAnimation(fig, update, frames=tqdm(range(len(predict))), interval=20, blit=True)\n",
    "ani.save(Path(f'./tmp/{file.stem}_inversion_vid.gif'), writer='Pillow')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
