{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from src.data.file_utils import GetTV\n",
    "from src.models import model, predict\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda x : x.reshape(len(x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ../models/weighted_outer_allold_set.pkl\n",
      "1 ../models/lr_tv_inv_outer.pkl\n",
      "2 ../models/weighted_outer_all.pkl\n",
      "3 ../models/weighted_outer_allnew_half_set.pkl\n",
      "4 ../models/lr_inversion_manual.pkl\n",
      "5 ../models/lr.pkl\n",
      "6 ../models/lr_supervised_mdl.pkl\n"
     ]
    }
   ],
   "source": [
    "models = predict.list_models()\n",
    "for idx, model in enumerate(models):\n",
    "    print(idx, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_type = 'l-mode'\n",
    "prep_filename = 'weighted_outer_dataset_' + run_type\n",
    "prediction_filename = 'weighted_outer_' + run_type\n",
    "algorithm = 'linear'\n",
    "split_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_path = Path('../data/raw/tv_images') / run_type\n",
    "label_path = Path('../data/labels/weighted_emission') / run_type\n",
    "prep_path = Path('../data/processed/hdf5')\n",
    "model_path = Path('../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = GetTV(tv_path)\n",
    "files = tv.list_files()\n",
    "file_lengths = tv.file_lengths()\n",
    "cumulative_lengths = np.insert(np.cumsum(file_lengths), 0, 0)\n",
    "tv_dim = tv.load(files[0], 'vid').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Out TV Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_split_compile_prep(split_ratio,\n",
    "                      prep_path,\n",
    "                      prep_filename,\n",
    "                      label_path,\n",
    "                      files):\n",
    "    # split by file\n",
    "    train_files, test_files = train_test_split(files, test_size=split_ratio, random_state=182)\n",
    "    [print(file.stem) for file in train_files]\n",
    "    print('-------------------')\n",
    "    [print(file.stem) for file in test_files]\n",
    "\n",
    "    points_train = []\n",
    "    tv_train = []\n",
    "    points_test = []\n",
    "    tv_test = []\n",
    "\n",
    "    for _, file in enumerate(train_files):\n",
    "        frames = tv.load(file, 'frames').astype('int')\n",
    "        tv_image = tv.load(file, 'vid')[frames]\n",
    "        \n",
    "        test_label_file = (label_path / file.stem).with_suffix('.pkl')\n",
    "        with open(test_label_file, 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "            \n",
    "        for i in range(len(frames)):\n",
    "            tv_train.append(tv_image[i])\n",
    "            points_train.append(labels[i])\n",
    "            \n",
    "    for _, file in enumerate(test_files):\n",
    "        frames = tv.load(file, 'frames').astype('int')\n",
    "        tv_image = tv.load(file, 'vid')[frames]\n",
    "        \n",
    "        test_label_file = (label_path / file.stem).with_suffix('.pkl')\n",
    "        with open(test_label_file, 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "            \n",
    "        for i in range(len(frames)):\n",
    "            tv_test.append(tv_image[i])\n",
    "            points_test.append(labels[i])\n",
    "            \n",
    "    with h5py.File(prep_path / str(prep_filename + '.h5'), 'w') as f:\n",
    "        f.create_dataset('vid_train', data=tv_train)\n",
    "        f.create_dataset('points_train', data=points_train)\n",
    "        f.create_dataset('vid_test', data=tv_test)\n",
    "        f.create_dataset('points_test', data=points_test)\n",
    "    print(str(prep_path / str(prep_filename + '.h5')),'has been saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission_structure_pu_cam240perp_190109\n",
      "emission_structure_pu_cam240perp_190110\n",
      "emission_structure_pu_cam240perp_190116\n",
      "emission_structure_pu_cam240perp_199166\n",
      "emission_structure_pu_cam240perp_199172\n",
      "emission_structure_pu_cam240perp_190113\n",
      "emission_structure_pu_cam240perp_199353\n",
      "emission_structure_pu_cam240perp_199354\n",
      "-------------------\n",
      "emission_structure_pu_cam240perp_190114\n",
      "emission_structure_pu_cam240perp_190115\n",
      "../data/processed/hdf5/weighted_outer_dataset_l-mode.h5 has been saved!\n"
     ]
    }
   ],
   "source": [
    "file_split_compile_prep(split_ratio, prep_path, prep_filename, label_path, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = prep_filename + '.h5'\n",
    "\n",
    "with h5py.File(prep_path / file_name, 'r') as f:\n",
    "    vid_train = f['vid_train'][:]\n",
    "    points_train = f['points_train'][:]\n",
    "    vid_test = f['vid_test'][:]\n",
    "    points_test = f['points_test'][:]\n",
    "\n",
    "files = tv.list_files()\n",
    "elevation = tv.load(files[0], 'elevation')[0]\n",
    "radii = tv.load(files[0], 'radii')[0]\n",
    "vid_shape = tv.load(files[0], 'vid')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = flatten(vid_train)\n",
    "X_test = flatten(vid_test)\n",
    "y_train = points_train # flatten(points_train)\n",
    "y_test = points_test # flatten(points_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LinearRegression<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = LinearRegression()\n",
    "mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.900937986032498\n"
     ]
    }
   ],
   "source": [
    "# mdl = pickle.load(open('../models/weighted_outer_allold_set.pkl', 'rb'))\n",
    "r_predict = mdl.predict(X_test)\n",
    "# real_predict = np.array([radii[np.round(r_predict[:,0]).astype(int)],elevation[np.round(r_predict[:,1]).astype(int)]]).T * 100 # from meter to cm (dimension is n x 2)\n",
    "# real_y = np.array([radii[np.round(y_test[:,0]).astype(int)],elevation[np.round(y_test[:,1]).astype(int)]]).T * 100\n",
    "err = mean_absolute_error(r_predict,y_test) * 100\n",
    "print(err)\n",
    "# z_err = np.abs(real_predict[:,1] - real_y[:,1])\n",
    "# print(f\"RMS (cm) : {np.sqrt(np.square(dist).mean())}\")\n",
    "# print(f\"Z RMS (cm) : {np.sqrt(np.square(z_err).mean())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0915888712356\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(r_predict,y_test))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old_set = before FY2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_id = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mdl, open(f\"{model_path / prediction_filename}{ml_id}.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_ml_point_save_path = Path('../data/processed/weight_ml_point') / ml_id\n",
    "weight_ml_point_save_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = pickle.load(open(f\"{model_path / prediction_filename}{ml_id}.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shot: 199354\n",
      "Saved ../data/labels/weighted_emission/all/emission_structure_pu_cam240perp_199354.txt\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('Shot:', file.stem.split('_')[-1])\n",
    "    point_save_name = weight_ml_point_save_path / f\"{file.stem}.pkl\"\n",
    "    label_file = (label_path / file.stem).with_suffix('.pkl')\n",
    "    with open(label_file, 'rb') as f:\n",
    "        labels_cartesian = pickle.load(f)\n",
    "    frames = tv.load(file, 'frames').astype('int')\n",
    "    tv_image = tv.load(file, 'vid')[frames]\n",
    "    tv_flatten = flatten(tv_image)\n",
    "    \n",
    "    prediction_cartesian = mdl.predict(tv_flatten)\n",
    "    txt_file = (label_path / file.stem).with_suffix('.txt')\n",
    "    with open(txt_file, 'w') as f:\n",
    "        for point in prediction_cartesian:\n",
    "            f.write(f\"{point},\")\n",
    "    print(f\"Saved {txt_file}\")\n",
    "    # pickle.dump(prediction_cartesian, open(point_save_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "with open(label_file, 'rb') as f:\n",
    "    labels_cartesian = pickle.load(f)\n",
    "    print(len(labels_cartesian))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 18:58:15.900847: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-03 18:58:16.178173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-03 18:58:16.250618: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-03 18:58:16.280191: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-03 18:58:16.454569: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-03 18:58:19.809179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = prep_filename + '.h5'\n",
    "\n",
    "with h5py.File(prep_path / file_name, 'r') as f:\n",
    "    vid_train = f['vid_train'][:]\n",
    "    points_train = f['points_train'][:]\n",
    "    vid_test = f['vid_test'][:]\n",
    "    points_test = f['points_test'][:]\n",
    "\n",
    "files = tv.list_files()\n",
    "elevation = tv.load(files[0], 'elevation')[0]\n",
    "radii = tv.load(files[0], 'radii')[0]\n",
    "vid_shape = tv.load(files[0], 'vid')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(720, 480, 1)),  # Input shape for grayscale image\n",
    "    Conv2D(32, (3, 3), activation='relu'),  # First Conv layer with ReLU\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # Second Conv layer with ReLU\n",
    "    MaxPooling2D(pool_size=(2, 2)),         # Max pooling layer with 2x2 pool size\n",
    "    Dropout(0.5),                           # Dropout layer with 50% dropout rate\n",
    "    Flatten(),                              # Flatten the output\n",
    "    Dense(128, activation='relu'),          # First fully connected layer with ReLU\n",
    "    Dropout(0.5),                           # Another Dropout layer\n",
    "    Dense(2)                                # Second fully connected layer (output layer)\n",
    "])\n",
    "\n",
    "# Compile the model using Adam optimizer and Mean Squared Error loss\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error', \n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data generators for data augmentation and training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=32)\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mse = model.evaluate(test_generator)\n",
    "\n",
    "print(f'Test loss (MSE): {test_loss}')\n",
    "print(f'Test MSE: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_index(array, value):\n",
    "    \"\"\"Find the index of the nearest value in an array.\"\"\"\n",
    "    return (np.abs(array - value)).argmin()\n",
    "\n",
    "def get_index(arr, coord):\n",
    "    # Get the insertion indices\n",
    "    ind = np.searchsorted(coord, arr)\n",
    "\n",
    "    # Correct the indices to point to the nearest actual index\n",
    "    ind = np.clip(ind, 0, len(coord) - 1)\n",
    "\n",
    "    # Now, adjust the indices to get the closest value\n",
    "    for i, cval in enumerate(arr):\n",
    "        if ind[i] > 0 and abs(cval - coord[ind[i] - 1]) < abs(cval - coord[ind[i]]):\n",
    "            ind[i] -= 1\n",
    "            \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda x : x.reshape(len(x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = GetTV(tv_path)\n",
    "files = tv.list_files()\n",
    "file_lengths = tv.file_lengths()\n",
    "cumulative_lengths = np.insert(np.cumsum(file_lengths), 0, 0)\n",
    "tv_dim = tv.load(files[0], 'vid').shape\n",
    "\n",
    "with open(f\"{model_path / prediction_filename}.pkl\", 'rb') as f:\n",
    "    mdl = pickle.load(f)\n",
    "    \n",
    "mp4_save_path = Path('../outputs/video/weighted_ml') / run_type\n",
    "mp4_save_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shot: 199354\n",
      "Animating...\n",
      "Saving MP4...\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('Shot:', file.stem.split('_')[-1])\n",
    "    mp4_save_name = mp4_save_path / f\"{file.stem.split('_')[-1]}.mp4\"\n",
    "    label_file = (label_path / file.stem).with_suffix('.pkl')\n",
    "    with open(label_file, 'rb') as f:\n",
    "        labels_cartesian = pickle.load(f)\n",
    "    frames = tv.load(file, 'frames').astype('int')\n",
    "    tv_image = tv.load(file, 'vid')[frames]\n",
    "    tv_flatten = flatten(tv_image)\n",
    "    inverted = tv.load(file, 'inverted')\n",
    "    elevation = tv.load(file, 'elevation')[0]\n",
    "    \n",
    "    prediction_cartesian = mdl.predict(tv_flatten)\n",
    "    \n",
    "    prediction = get_index(prediction_cartesian, elevation, )\n",
    "    labels = get_index(labels_cartesian, elevation)\n",
    "\n",
    "    # Initialize figure and axes\n",
    "    print(\"Animating...\")\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    \n",
    "    img = ax.imshow(inverted[0], origin='lower')\n",
    "    hline_label = ax.axhline(labels[0], c='lime', label='label')\n",
    "    hline_prediction = ax.axhline(prediction[0], c='red', label='prediction', ls='--')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title(f'Inverted View: 0')\n",
    "\n",
    "    fig.suptitle(f\"Shot {file.stem.split('_')[-1]}\")\n",
    "    frames = []\n",
    "    # Function to update the plot\n",
    "    def update(idx):\n",
    "        img.set_data(inverted[idx])\n",
    "        \n",
    "        hline_label.set_ydata([labels[idx]])\n",
    "        hline_prediction.set_ydata([prediction[idx]])\n",
    "        \n",
    "        ax.set_title(f'Inverted View: {idx}')\n",
    "        \n",
    "        return img, hline_label, hline_prediction\n",
    "        \n",
    "    # Create the animation using FuncAnimation\n",
    "    ani = animation.FuncAnimation(fig, update, frames=range(inverted.shape[0]), blit=True, repeat=False)\n",
    "\n",
    "    # Save the animation as an MP4 file\n",
    "    print(\"Saving MP4...\")\n",
    "    FFwriter = animation.FFMpegWriter(fps=30, extra_args=[\"-vcodec\", \"libx264\"])\n",
    "    ani.save(mp4_save_name, writer=FFwriter)\n",
    "\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
