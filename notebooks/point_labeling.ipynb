{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_find_index' from 'src.data.file_utils' (/Users/nc1514/Documents/GitHub/plasma-tv/src/data/file_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GetTV, _find_index\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_find_index' from 'src.data.file_utils' (/Users/nc1514/Documents/GitHub/plasma-tv/src/data/file_utils.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import cv2\n",
    "import h5py\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from src.data.file_utils import GetTV, _find_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Point Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageTk\n",
    "from tkinter import Tk, Label\n",
    "\n",
    "from src.external.labeling import manual_labeling as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_idx = 2  # Index of the file to be loaded\n",
    "root = Tk()\n",
    "tv_image_path = Path(\"tv_images/l-mode\")\n",
    "output_path = Path(\"../outputs/manual_labeled_points\")\n",
    "\n",
    "tv = GetTV(tv_image_path)\n",
    "files = tv.list_files()\n",
    "file = files[file_idx]\n",
    "inverted = tv.load(file, \"inverted\")\n",
    "out_file = output_path / Path(file.stem).with_suffix(\".csv\")\n",
    "photos = (255 * (inverted - np.min(inverted)) / (np.max(inverted) - np.min(inverted))).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_photo_index = 0\n",
    "photo = ImageTk.PhotoImage(image=Image.fromarray(photos[current_photo_index]))\n",
    "photo = photo._PhotoImage__photo.zoom(4)\n",
    "w = Label(root, image=photo)\n",
    "w.pack()\n",
    "\n",
    "coordinates = []\n",
    "\n",
    "root.bind(\"<Right>\", ml.next_photo)\n",
    "root.bind(\"<Left>\", ml.previous_photo)\n",
    "w.bind(\"<Button-1>\", ml.callback)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Point Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.external.labeling import auto_labeling as al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_idx = 0\n",
    "tv = GetTV('tv_images/l-mode')\n",
    "files = tv.list_files()\n",
    "[inverted,radii,elevation,frames,times,vid_frames,vid_times,vid] = tv.load_all(files[file_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize values\n",
    "x_0 = np.array([1.30,-1.05]) # x-point location\n",
    "l_0 = np.array([1.05,-1.21]) # left radiation point location\n",
    "r_0 = np.array([1.48,-1.25]) # right radiation point location\n",
    "\n",
    "centers_0 = np.array([al.convert_center(radii,elevation,x_0),\n",
    "                      al.convert_center(radii,elevation,l_0),\n",
    "                      al.convert_center(radii,elevation,r_0)])\n",
    "\n",
    "radius = 6 # for some reason, 6 just works the best while every other value doesn't work\n",
    "threshold = 0.05 # intensity value threshold for points to update their position\n",
    "merge_threshold = 20 # merge threshold for radiation point and X-point, should be on factor of 2X radius\n",
    "distance_threshold = 10 # distance from emission line for corner to be considered a radiation point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate Across All Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_idx = 0\n",
    "tv = GetTV('tv_images/l-mode')\n",
    "files = tv.list_files()\n",
    "[inverted,radii,elevation,frames,times,vid_frames,vid_times,vid] = tv.load_all(files[file_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize values\n",
    "x_0 = np.array([1.30,-1.05]) # x-point location\n",
    "l_0 = np.array([1.05,-1.21]) # left radiation point location\n",
    "r_0 = np.array([1.48,-1.25]) # right radiation point location\n",
    "\n",
    "centers_0 = np.array([al.convert_center(radii,elevation,x_0),\n",
    "                      al.convert_center(radii,elevation,l_0),\n",
    "                      al.convert_center(radii,elevation,r_0)])\n",
    "\n",
    "radius = 6 # for some reason, 6 just works the best while every other value doesn't work\n",
    "threshold = 0.05 # intensity value threshold for points to update their position\n",
    "merge_threshold = 20 # merge threshold for radiation point and X-point, should be on factor of 2X radius\n",
    "distance_threshold = 10 # distance from emission line for corner to be considered a radiation point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Point Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('../out/hdf5')\n",
    "model_file_path = Path('../models')\n",
    "file_name = 'inversion_manual.hdf5'\n",
    "file_name = file_path / file_name\n",
    "\n",
    "tv = GetTV()\n",
    "files = tv.list_files()\n",
    "elevation = tv.load(files[0], 'elevation')[0]\n",
    "radii = tv.load(files[0], 'radii')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(file_name, 'r') as f:\n",
    "    inverted = f['inverted'][:]\n",
    "    points = f['points'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = inverted.copy()\n",
    "X_train, X_test_raw, y_train, y_test = train_test_split(image, points, test_size=0.2)\n",
    "X_train = X_train.reshape((len(X_train), -1))\n",
    "X_test = X_test_raw.reshape((len(X_test_raw), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression() # try ridge regression\n",
    "regr.fit(X_train, y_train)\n",
    "r_sq = regr.score(X_test, y_test)\n",
    "r_predict = regr.predict(X_test)\n",
    "print(r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMS (cm) : {np.sqrt(mean_squared_error(y_test, r_predict))*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = image.reshape((len(image), -1))\n",
    "print(image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_dump = LinearRegression()\n",
    "regr_dump.fit(image2, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = model_file_path / Path('lr_supervised_mdl').with_suffix('.pkl')\n",
    "pickle.dump(regr_dump, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = model_file_path / Path('lr_supervised_mdl').with_suffix('.pkl')\n",
    "loaded_model = pickle.load(open(model_filename, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
