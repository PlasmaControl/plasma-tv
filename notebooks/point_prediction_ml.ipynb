{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from src.data.file_utils import GetTV\n",
    "from src.models import model, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ../models/.gitignore\n",
      "1 ../models/lr_inversion_points.pkl\n"
     ]
    }
   ],
   "source": [
    "models = predict.list_models()\n",
    "for idx, model in enumerate(models):\n",
    "    print(idx, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_filename = 'tv_inv_outer'\n",
    "prediction_filename = 'lr'\n",
    "algorithm = 'linear'\n",
    "inversion_to_point_model_index = 1\n",
    "split_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_path = Path('../data/raw/tv_images')\n",
    "label_path = Path('../data/processed/inversion_data')\n",
    "prep_path = Path('../data/processed/hdf5')\n",
    "model_path = Path('../models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = GetTV(tv_path)\n",
    "files = tv.list_files()\n",
    "file_lengths = tv.file_lengths()\n",
    "cumulative_lengths = np.insert(np.cumsum(file_lengths), 0, 0)\n",
    "tv_dim = tv.load(files[0], 'vid').shape\n",
    "inversion_dim = tv.load(files[0], 'inverted').shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_split_compile_prep(split_ratio,\n",
    "                      prep_path,\n",
    "                      prep_filename,\n",
    "                      files):\n",
    "    # split by file\n",
    "    train_files, test_files = train_test_split(files, test_size=split_ratio, random_state=30)\n",
    "    [print(file.stem) for file in train_files]\n",
    "    print('-------------------')\n",
    "    [print(file.stem) for file in test_files]\n",
    "\n",
    "    points_train = []\n",
    "    tv_train = []\n",
    "    inverted_train = []\n",
    "    points_test = []\n",
    "    tv_test = []\n",
    "    inverted_test = []\n",
    "    \n",
    "    with open(models[inversion_to_point_model_index], 'rb') as f:\n",
    "        inversion_model = pickle.load(f)\n",
    "\n",
    "    for _, file in enumerate(train_files):\n",
    "        frames = tv.load(file, 'frames').astype('int')\n",
    "        tv_image = tv.load(file, 'vid')[frames]\n",
    "        inversion = tv.load(file, 'inverted')\n",
    "        inversion_vid2 = inversion.reshape((len(inversion), -1))\n",
    "        for i in range(len(frames)):\n",
    "            tv_train.append(tv_image[i])\n",
    "            inverted_train.append(inversion[i])\n",
    "            points_train.append(inversion_model.predict(inversion_vid2[i].reshape(1, -1)))\n",
    "            \n",
    "    for _, file in enumerate(test_files):\n",
    "        frames = tv.load(file, 'frames').astype('int')\n",
    "        tv_image = tv.load(file, 'vid')[frames]\n",
    "        inversion = tv.load(file, 'inverted')\n",
    "        inversion_vid2 = inversion.reshape((len(inversion), -1))\n",
    "        for i in range(len(frames)):\n",
    "            tv_test.append(tv_image[i])\n",
    "            inverted_test.append(inversion[i])\n",
    "            points_test.append(inversion_model.predict(inversion_vid2[i].reshape(1, -1)))\n",
    "            \n",
    "    with h5py.File(prep_path / str(prep_filename + '.h5'), 'w') as f:\n",
    "        f.create_dataset('vid_train', data=tv_train)\n",
    "        f.create_dataset('inverted_train', data=inverted_train)\n",
    "        f.create_dataset('points_train', data=points_train)\n",
    "        f.create_dataset('vid_test', data=tv_test)\n",
    "        f.create_dataset('inverted_test', data=inverted_test)\n",
    "        f.create_dataset('points_test', data=points_test)\n",
    "    print(str(prep_path / str(prep_filename + '.h5')),'has been saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission_structure_pu_cam240perp_190114\n",
      "emission_structure_pu_cam240perp_189057\n",
      "emission_structure_pu_cam240perp_189088\n",
      "emission_structure_pu_cam240perp_189101\n",
      "emission_structure_pu_cam240perp_190113\n",
      "emission_structure_pu_cam240perp_189061\n",
      "emission_structure_pu_cam240perp_189081\n",
      "emission_structure_pu_cam240perp_189100\n",
      "emission_structure_pu_cam240perp_189090\n",
      "emission_structure_pu_cam240perp_189094\n",
      "-------------------\n",
      "emission_structure_pu_cam240perp_189062\n",
      "emission_structure_pu_cam240perp_189097\n",
      "emission_structure_pu_cam240perp_189093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nc1514/Documents/GitHub/plasma-tv/.venv/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.3.0 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/processed/hdf5/tv_inv_outer.h5 has been saved!\n"
     ]
    }
   ],
   "source": [
    "file_split_compile_prep(split_ratio, prep_path, prep_filename, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = prep_filename + '.h5'\n",
    "\n",
    "with h5py.File(prep_path / file_name, 'r') as f:\n",
    "    vid_train = f['vid_train'][:]\n",
    "    inverted_train = f['inverted_train'][:]\n",
    "    points_train = f['points_train'][:]\n",
    "    vid_test = f['vid_test'][:]\n",
    "    inverted_test = f['inverted_test'][:]\n",
    "    points_test = f['points_test'][:]\n",
    "\n",
    "files = tv.list_files()\n",
    "elevation = tv.load(files[0], 'elevation')[0]\n",
    "radii = tv.load(files[0], 'radii')[0]\n",
    "vid_shape = tv.load(files[0], 'vid')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vid_train.reshape((len(vid_train), -1))\n",
    "X_test = vid_test.reshape((len(vid_test), -1))\n",
    "y_train = points_train.reshape((len(points_train), -1))\n",
    "y_test = points_test.reshape((len(points_test), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = LinearRegression()\n",
    "mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = mdl.score(X_test, y_test)\n",
    "r_predict = mdl.predict(X_test)\n",
    "real_predict = np.array([radii[np.round(r_predict[:,0]).astype(int)],elevation[np.round(r_predict[:,1]).astype(int)]]).T\n",
    "real_y = np.array([radii[np.round(y_test[:,0]).astype(int)],elevation[np.round(y_test[:,1]).astype(int)]]).T\n",
    "print(r_sq)\n",
    "print(f\"RMS (cm) : {np.sqrt(mean_squared_error(real_predict, real_y)*100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = mdl.coef_\n",
    "intercept = mdl.intercept_\n",
    "with open(model_file_path / 'lr_coef.txt', 'w') as f:\n",
    "    for i in range(coef.shape[1]):\n",
    "        f.write(str(coef[0][i]) + '\\n')\n",
    "    for i in range(coef.shape[1]):\n",
    "        f.write(str(coef[1][i]) + '\\n')\n",
    "\n",
    "with open(model_file_path / 'lr_intercept.txt', 'w') as f:\n",
    "    for i in range(intercept.shape[0]):\n",
    "        f.write(str(intercept[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsampling functions\n",
    "downsample2d = lambda x, factor : x[:, ::factor, ::factor]\n",
    "flatten = lambda x : x.reshape(len(x), -1)\n",
    "\n",
    "def regr_scoring(X_train, X_test, y_train, y_test):\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X_train, y_train)\n",
    "    r_predict = regr.predict(X_test)\n",
    "    real_predict = np.array([radii[np.round(r_predict[:,0]).astype(int)],elevation[np.round(r_predict[:,1]).astype(int)]]).T * 100 # from meter to cm (dimension is n x 2)\n",
    "    real_y = np.array([radii[np.round(y_test[:,0]).astype(int)],elevation[np.round(y_test[:,1]).astype(int)]]).T * 100\n",
    "    dist = np.linalg.norm(real_predict - real_y, axis=1)\n",
    "    z_err = np.abs(real_predict[:,1] - real_y[:,1])\n",
    "    return r_predict, dist, z_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "downsamples = range(1,10)\n",
    "numpixel_array = []\n",
    "r_sq_array = []\n",
    "rms_array = []\n",
    "rms_z_err_array = []\n",
    "\n",
    "for n in downsamples:\n",
    "    print(n)\n",
    "    vid_train_down = downsample2d(vid_train, n)\n",
    "    vid_test_down = downsample2d(vid_test, n)\n",
    "    \n",
    "    vid_train_down_reshape = flatten(vid_train_down)\n",
    "    vid_test_down_reshape = flatten(vid_test_down)\n",
    "    points_train_reshape = flatten(points_train)\n",
    "    points_test_reshape = flatten(points_test)\n",
    "    \n",
    "    numpixel = vid_train_down_reshape.shape[1]\n",
    "    \n",
    "    _, dist, z_err = regr_scoring(vid_train_down_reshape, vid_test_down_reshape, points_train_reshape, points_test_reshape)\n",
    "    \n",
    "    numpixel_array.append(numpixel)\n",
    "    r_sq_array.append(r_sq)\n",
    "    rms_array.append(np.sqrt(np.square(dist).mean()))\n",
    "    rms_z_err_array.append(np.sqrt(np.square(z_err).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
