{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.io import readsav\n",
    "import h5py\n",
    "import pickle\n",
    "import cv2\n",
    "# import diplib as dip\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness_reconstruction(img): # doi: 10.1109/TPS.2018.2828863.\n",
    "    im_norm = img / 255\n",
    "    img = np.average(im_norm,axis=None)\n",
    "    img = np.log(im_norm + 1) * (im_norm - img)\n",
    "    img = img / np.max(img)\n",
    "    img = np.where(img < 0, 0, img)\n",
    "    return img * 255\n",
    "\n",
    "def process_image(img, kernel_size, sigma, threshold, erode_kernel):\n",
    "    # img = cv2.GaussianBlur(img,(kernel_size, kernel_size),0)\n",
    "    img = brightness_reconstruction(img)\n",
    "    # img = np.array(dip.MatchedFiltersLineDetector2D(img, sigma = sigma)) # 10.1109/42.34715\n",
    "    img *= 255.0/img.max()\n",
    "    img = brightness_reconstruction(img)\n",
    "    img = np.where(img < threshold, 0, 1).astype('uint8')\n",
    "    # img = cv2.erode(img, np.ones((erode_kernel,erode_kernel), np.uint8), iterations=1)\n",
    "    return img\n",
    "\n",
    "def canny(img):\n",
    "    # gray=(255-255*(img-np.min(img))/(np.max(img)-np.min(img))).astype('uint8')\n",
    "\n",
    "    # reduce the noise using Gaussian filters\n",
    "    kernel_size = 11 \n",
    "    blur_gray = cv2.GaussianBlur(img,(kernel_size, kernel_size),0)\n",
    "\n",
    "    # Apply Canny edge detctor\n",
    "    low_threshold = 10\n",
    "    high_threshold = 20\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "\n",
    "1. Loop across all files\n",
    "1. Loop across all indicies in file\n",
    "1. Get processed image, and r,l datapoints\n",
    "1. Append to 3 arrays\n",
    "1. After each full run, save process image array, r, l datapoint to hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_image_path = Path('tv_images')\n",
    "inversion_data_path = Path('outputs/inversion_data')\n",
    "hdf5_path = Path('outputs/hdf5')\n",
    "files = sorted(tv_image_path.glob('*.sav'))\n",
    "file_lengths = [len(readsav(str(file))['emission_structure'][0][3]) for file in files]\n",
    "cumulative_lengths = np.insert(np.cumsum(file_lengths), 0, 0)\n",
    "tv_dim = readsav(str(files[0]))['emission_structure'][0][7][0].shape\n",
    "inversion_dim = readsav(str(files[0]))['emission_structure'][0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tv_dim)\n",
    "print(inversion_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_dim = (240, 480)\n",
    "kernel_size = 5\n",
    "sigma = 1\n",
    "threshold = 4\n",
    "erode_kernel = 4\n",
    "aspect_num = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file_name = hdf5_path / 'tv_raw.hdf5'\n",
    "hf = h5py.File(hdf5_file_name, 'w') # open h5py file\n",
    "tv_dataset = hf.create_dataset(\"tv_images\", shape=(np.sum(file_lengths), tv_dim[0], tv_dim[1]), dtype='uint8')\n",
    "points_dataset = hf.create_dataset(\"points\", shape=(np.sum(file_lengths), 4), dtype='float32')\n",
    "\n",
    "# Add datasets to the groups\n",
    "for idx, file in enumerate(files):\n",
    "    frames = readsav(file)['emission_structure'][0][3].astype(int)\n",
    "    tv_image = readsav(file)['emission_structure'][0][7][frames]\n",
    "    tv_image_process = np.asarray(tv_image) # faster process and convert to binary\n",
    "    pkl_path = (inversion_data_path / file.stem).with_suffix('.pkl')\n",
    "    with open(pkl_path, 'rb') as pkl_file:\n",
    "            label_info = pickle.load(pkl_file)\n",
    "    points = np.concatenate((label_info['l_location'], label_info['r_location']),1)\n",
    "    \n",
    "    for i in range(file_lengths[idx]):\n",
    "        tv_dataset[cumulative_lengths[idx]+i] = tv_image_process[i]\n",
    "        points_dataset[cumulative_lengths[idx]+i] = points[i]\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file_name = hdf5_path / 'tv_process_simple.hdf5'\n",
    "hf = h5py.File(hdf5_file_name, 'w') # open h5py file\n",
    "tv_dataset = hf.create_dataset(\"tv_images\", shape=(np.sum(file_lengths), crop_dim[0], crop_dim[1]), dtype='uint8')\n",
    "points_dataset = hf.create_dataset(\"points\", shape=(np.sum(file_lengths), 4), dtype='float32')\n",
    "\n",
    "# Add datasets to the groups\n",
    "for idx, file in enumerate(files):\n",
    "    print(f\"{idx+1} of {len(files)}\")\n",
    "    frames = readsav(file)['emission_structure'][0][3].astype(int)\n",
    "    tv_image = readsav(file)['emission_structure'][0][7][frames]\n",
    "    pkl_path = (inversion_data_path / file.stem).with_suffix('.pkl')\n",
    "    with open(pkl_path, 'rb') as pkl_file:\n",
    "            label_info = pickle.load(pkl_file)\n",
    "    points = np.concatenate((label_info['l_location'], label_info['r_location']),1)\n",
    "    \n",
    "    for i in range(file_lengths[idx]):\n",
    "        tv_dataset[cumulative_lengths[idx]+i] = np.asarray(process_image(tv_image[i, 0:240, 240:720],kernel_size, sigma, threshold, erode_kernel))\n",
    "        points_dataset[cumulative_lengths[idx]+i] = points[i]\n",
    "    clear_output()\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file_name = hdf5_path / 'compiled_inversion_no_image.hdf5'\n",
    "hf = h5py.File(hdf5_file_name, 'w') # open h5py file\n",
    "rz_dataset = hf.create_dataset(\"rz\", shape=(np.sum(file_lengths), 4), dtype='float32')\n",
    "intensity_dataset = hf.create_dataset(\"intensity\", shape=(np.sum(file_lengths), 2), dtype='float32')\n",
    "\n",
    "# Add datasets to the groups\n",
    "for idx, file in enumerate(files):\n",
    "    pkl_path = (inversion_data_path / file.stem).with_suffix('.pkl')\n",
    "    with open(pkl_path, 'rb') as pkl_file:\n",
    "            label_info = pickle.load(pkl_file)\n",
    "    points = np.concatenate((label_info['l_location'], label_info['r_location']),1)\n",
    "    points_i = np.concatenate((label_info['l_intensity'], label_info['r_intensity']))\n",
    "\n",
    "    for i in range(file_lengths[idx]):\n",
    "            rz_dataset[cumulative_lengths[idx]+i] = points[i]\n",
    "            intensity_dataset[cumulative_lengths[idx]+i] = points_i[i]\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file_name = hdf5_path / 'x_outer_radiation.hdf5'\n",
    "hf = h5py.File(hdf5_file_name, 'w') # open h5py file\n",
    "tv_dataset = hf.create_dataset(\"tv_images\", shape=(np.sum(file_lengths), tv_dim[0], tv_dim[1]), dtype='uint8')\n",
    "points_dataset = hf.create_dataset(\"points\", shape=(np.sum(file_lengths), 4), dtype='float32')\n",
    "intensity_dataset = hf.create_dataset(\"intensity\", shape=(np.sum(file_lengths), 2), dtype='float32')\n",
    "print(files)\n",
    "# Add datasets to the groups\n",
    "for idx, file in enumerate(files):\n",
    "    frames = readsav(file)['emission_structure'][0][3].astype(int)\n",
    "    tv_image = readsav(file)['emission_structure'][0][7][frames]\n",
    "    tv_image_process = np.asarray(tv_image) # faster process and convert to binary\n",
    "    pkl_path = (inversion_data_path / file.stem).with_suffix('.pkl')\n",
    "    with open(pkl_path, 'rb') as pkl_file:\n",
    "            label_info = pickle.load(pkl_file)\n",
    "    points = np.concatenate((label_info['x_location'], label_info['r_location']),1)\n",
    "    points_i = np.concatenate((label_info['x_intensity'], label_info['r_intensity']))\n",
    "    \n",
    "    for i in range(file_lengths[idx]):\n",
    "        tv_dataset[cumulative_lengths[idx]+i] = tv_image_process[i]\n",
    "        points_dataset[cumulative_lengths[idx]+i] = points[i]\n",
    "        intensity_dataset[cumulative_lengths[idx]+i] = points_i[i]\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split HDF5 into Train/Test/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomization = False\n",
    "tts_percent = 0.6\n",
    "tvs_percent = 0.8\n",
    "\n",
    "file_name_1 = Path('outputs/hdf5/s_outs_v3_limited.h5')\n",
    "file_name_2 = Path('outputs/hdf5/x_outer_radiation.hdf5')\n",
    "\n",
    "out_path = Path('outputs')\n",
    "\n",
    "\n",
    "with h5py.File(file_name_1, 'r') as f:\n",
    "    synthetic_images = f['image'][:] * 2 - 1\n",
    "    \n",
    "with h5py.File(file_name_2, 'r') as f:\n",
    "    points = f['points'][:]\n",
    "    tv_images = f['tv_images'][:] / 127.5 - 1\n",
    "    \n",
    "file_len = len(points)\n",
    "\n",
    "crop_synthetic = np.zeros((file_len, 256, 256))\n",
    "crop_tv = np.zeros((file_len, 256, 256))\n",
    "\n",
    "for i in tqdm(range(file_len)):\n",
    "    crop_synthetic[i] = resize(synthetic_images[i], (256, 256))\n",
    "    crop_tv[i] = np.flip(resize(tv_images[i], (256, 256)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_dat, synth_val, tv_dat, tv_val = train_test_split(crop_synthetic, crop_tv, train_size=tts_percent, random_state=42)\n",
    "synth_train, synth_test, tv_train, tv_test = train_test_split(synth_dat, tv_dat, train_size=tvs_percent, random_state=42)\n",
    "\n",
    "with h5py.File(out_path / 'img2img.h5', 'w') as f:\n",
    "    f.create_dataset('synth_train', data=synth_train)\n",
    "    f.create_dataset('synth_test', data=synth_test)\n",
    "    f.create_dataset('synthval', data=synth_val)\n",
    "    f.create_dataset('tv_train', data=tv_train)\n",
    "    f.create_dataset('tv_test', data=tv_test)\n",
    "    f.create_dataset('tv_val', data=tv_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs1 = plt.subplot(1,2,1)\n",
    "axs1.imshow(crop_tv[211], origin='lower')\n",
    "axs2 = plt.subplot(1,2,2)\n",
    "axs2.imshow(crop_synthetic[10], origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_indices = []\n",
    "\n",
    "for i in range(len(crop_tv)):\n",
    "    clear_output()\n",
    "    axs1 = plt.subplot(1,2,1)\n",
    "    axs1.imshow(crop_tv[i], origin='lower')\n",
    "    axs2 = plt.subplot(1,2,2)\n",
    "    axs2.imshow(crop_synthetic[i], origin='lower')\n",
    "    plt.show()\n",
    "    print(f\"Index: {i}\")\n",
    "    response = input(\"Press 'n' if invalid index: \")\n",
    "    if response.lower() == 'n':\n",
    "        skip_indices.append(i)\n",
    "    clear_output()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
