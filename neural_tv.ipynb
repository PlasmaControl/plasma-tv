{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('.\\hdf5')\n",
    "file_names = ['tv_raw.hdf5', 'tv_crop.hdf5', 'tv_process.hdf5']\n",
    "file_name = file_path / file_names[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(file_name, 'r') as f:\n",
    "    target = f['tv_images'][:]\n",
    "    label = f['points'][:]\n",
    "\n",
    "target_norm = np.mean(target)\n",
    "target_std = np.std(target)\n",
    "label_norm = np.mean(label,axis=0)\n",
    "label_std = np.std(label,axis=0)\n",
    "\n",
    "del target\n",
    "del label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"target_mean: {target_norm:.4f}\")\n",
    "print(f\"target_std: {target_std:.4f}\")\n",
    "print(f\"label_mean: {label_norm}\")\n",
    "print(f\"label_std: {label_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVDataset(Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.file_path = file_path\n",
    "        self.file = h5py.File(file_path, 'r')\n",
    "        self.target = self.file['tv_images'][:][:, np.newaxis, ...]\n",
    "        self.label = self.file['points'][:]\n",
    "        self.transform = transform\n",
    "        if self.transform:\n",
    "            self.target, self.label = self.transform(self.target, self.label)\n",
    "        self.file.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target = self.target[idx]\n",
    "        label = self.label[idx]\n",
    "        return target, label\n",
    "\n",
    "class CustomTransform:\n",
    "    def __init__(self, target_norm, label_norm, target_std, label_std):\n",
    "        self.target_norm = target_norm\n",
    "        self.label_norm = label_norm\n",
    "        self.target_std = target_std\n",
    "        self.label_std = label_std\n",
    "\n",
    "    def __call__(self, target, label):\n",
    "        target = (target - self.target_norm) / self.target_std\n",
    "        label = (label - self.label_norm) / self.label_std\n",
    "        return torch.tensor(target).float(), torch.tensor(label).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(8, 8)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(672 , 128)\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, n_epochs, device):\n",
    "    model.train()\n",
    "    loss_norm = len(dataloader.dataset)\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "        print(f'{epoch + 1} loss: {running_loss / loss_norm:.3}')\n",
    "\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvNet().to(device)\n",
    "summary(model, input_size = (1, 240, 480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = CustomTransform(target_norm, label_norm, target_std, label_std)\n",
    "test_dataset = TVDataset(file_name, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"dataset length = {len(test_dataset)}\")\n",
    "print(f'label = {test_dataset[0][1]}')\n",
    "im_ratio = test_dataset[0][0][0].shape[1]/test_dataset[0][0][0].shape[0]\n",
    "plt.imshow(test_dataset[0][0][0], cmap = 'plasma')\n",
    "plt.colorbar(orientation=\"horizontal\",fraction=0.047*im_ratio)\n",
    "plt.title(\"target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "n_epochs = 100\n",
    "\n",
    "model = train_model(model, dataloader, optimizer, criterion, n_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have loaded the new dataset into a variable named `new_dataset`\n",
    "# and created a dataloader for it named `new_dataloader`\n",
    "new_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "n_samples = len(new_dataloader.dataset)\n",
    "output_size = model.fc2.out_features\n",
    "predicted = np.zeros((n_samples, output_size))\n",
    "actual = np.zeros((n_samples, output_size))\n",
    "model.eval()\n",
    "\n",
    "# Iterate over the dataloader and predict the output for each input\n",
    "with torch.no_grad():\n",
    "    start_index = 0\n",
    "    for inputs, actual_outputs in new_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        predicted_outputs = model(inputs)\n",
    "        end_index = start_index + predicted_outputs.shape[0]\n",
    "        predicted[start_index:end_index] = predicted_outputs.cpu().numpy()\n",
    "        actual[start_index:end_index] = actual_outputs.numpy()\n",
    "        start_index = end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renorm_actual = dataloader.dataset[:][1].numpy() * label_std + label_norm\n",
    "renorm_predicted = predicted * label_std + label_norm\n",
    "\n",
    "print(renorm_actual)\n",
    "print(renorm_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum((new_dataloader.dataset[:][1].numpy() - predicted)**2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create scatter plots\n",
    "scat_pred = ax.scatter([], [], c='lime', label='predicted')\n",
    "scat_actual = ax.scatter([], [], c='red', label='actual')\n",
    "\n",
    "def update(num):\n",
    "    x1, y1, x2, y2 = renorm_predicted[num]\n",
    "    a1, b1, a2, b2 = renorm_actual[num]\n",
    "    scat_pred.set_offsets(np.c_[[x1, x2], [y1, y2]])\n",
    "    scat_actual.set_offsets(np.c_[[a1, a2], [b1, b2]])\n",
    "    return scat_pred, scat_actual\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlim([0,201])\n",
    "ax.set_ylim([0,201])\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=range(len(predicted)), interval=30, blit=True, repeat=False)\n",
    "\n",
    "ani.save(Path('./tmp/animation.mp4'), writer='ffmpeg', fps=60)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
