{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from pathlib import Path\n",
    "from scipy.io import readsav\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(filename):\n",
    "    dat = readsav(filename)\n",
    "    emission = dat['emission_structure']\n",
    "    return emission[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = Path('tv_images')\n",
    "label_path = Path('inversion_data')\n",
    "\n",
    "target_names = [f for f in target_path.glob('*') if f.is_file()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Point Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_idx = 0\n",
    "data_idx = 0\n",
    "# inverted, radii, elevation, frames, times, vid_frames, vid_times, vid\n",
    "[inverted,_,_,frames,_,_,_,vid] = _load_data(target_names[file_idx])\n",
    "# frame, x_location, l_location, r_location, x_intensity, l_intensity, r_intensity\n",
    "pkl_path = (label_path / target_names[file_idx].stem).with_suffix('.pkl') # target and label have same name stem\n",
    "pkl_file = open(pkl_path, 'rb')\n",
    "label_info = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "invert_idx = frames.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_point = label_info['l_location'][data_idx]\n",
    "r_point = label_info['r_location'][data_idx]\n",
    "print(f\"left point = {l_point}\")\n",
    "print(f\"right point = {r_point}\")\n",
    "# test thing for github\n",
    "label_norm = inverted[0].shape[0]\n",
    "target_norm = 255\n",
    "print(f\"label normalization = {label_norm}\")\n",
    "\n",
    "plt.imshow(inverted[data_idx], cmap = 'plasma')\n",
    "plt.scatter(l_point[0],l_point[1],c='lime',s=1)\n",
    "plt.scatter(r_point[0],r_point[1],c='lime',s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_point = vid[invert_idx[data_idx]] / target_norm\n",
    "label_point = np.array([label_info['l_location'][data_idx], label_info['r_location'][data_idx]]).ravel() / label_norm\n",
    "print(f\"label = {label_point}\")\n",
    "\n",
    "im_ratio = target_point.shape[1]/target_point.shape[0]\n",
    "plt.imshow(target_point, vmin=0, vmax=1, cmap = 'plasma')\n",
    "plt.colorbar(orientation=\"horizontal\",fraction=0.047*im_ratio)\n",
    "plt.title(\"target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVDataset(Dataset):\n",
    "    def __init__(self, target_path, label_path, file_name):\n",
    "        self.target_path = target_path\n",
    "        self.label_path = label_path\n",
    "        self.file_name = file_name\n",
    "        self.pkl_path = (self.label_path / self.file_name.stem).with_suffix('.pkl')\n",
    "        self.target_norm = 255\n",
    "        self.label_norm = 201\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(readsav(self.file_name)['emission_structure'][0][3]) # gets length of frames\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        frame = readsav(self.file_name)['emission_structure'][0][3][idx]\n",
    "        target = readsav(self.file_name)['emission_structure'][0][7][int(frame)] / self.target_norm\n",
    "        target = np.array([target])\n",
    "        with open(self.pkl_path, 'rb') as pkl_file:\n",
    "            label_info = pickle.load(pkl_file)\n",
    "        label = np.array([label_info['l_location'][idx], label_info['r_location'][idx]]).ravel() / self.label_norm\n",
    "        target_tensor = torch.from_numpy(target)\n",
    "        label_tensor = torch.from_numpy(label)\n",
    "        return target_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to do this with all videos now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TVDataset(target_path, label_path, target_names[file_idx])\n",
    "print(f'label = {test_dataset[0][1]}')\n",
    "plt.imshow(test_dataset[0][0][0], vmin=0, vmax=1, cmap = 'plasma')\n",
    "plt.colorbar(orientation=\"horizontal\",fraction=0.047*im_ratio)\n",
    "plt.title(\"target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched[0].size(),\n",
    "          sample_batched[1].size())\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 60 * 180, 128)\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)  # Add sigmoid activation to the final layer\n",
    "        return x\n",
    "    \n",
    "model = ConvNeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "n_mini = len(dataloader)\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20== 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataloader with the sample dataset\n",
    "sample_dataset = TVDataset(target_path, label_path, target_names[file_idx])\n",
    "sample_dataloader = DataLoader(sample_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "# set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# initialize the loss and accuracy\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# iterate over the sample dataloader\n",
    "with torch.no_grad():\n",
    "    for data in sample_dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        outputs = model(inputs)\n",
    "        print(outputs)\n",
    "        print(labels)\n",
    "        test_loss += loss_fn(outputs, labels).item()\n",
    "        print(test_loss)\n",
    "        total += labels.size(0)\n",
    "        break\n",
    "\n",
    "# calculate the loss and accuracy\n",
    "test_loss /= len(sample_dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TVDataset(target_path, label_path, target_names[file_idx])\n",
    "# print(f'label = {test_dataset[0][1]}')\n",
    "tensor_test = test_dataset[0][0].unsqueeze(0)\n",
    "predicted = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        data = test_dataset[i][0].unsqueeze(0)\n",
    "        predicted.append(model(data.float().to(device)).cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def update(num):\n",
    "    ax.clear()\n",
    "    x1, y1, x2, y2 = predicted[num]\n",
    "    a1, b1, a2, b2 = test_dataset[num][1].numpy()\n",
    "    ax.scatter(x1, y1, c='lime', label= 'predicted')\n",
    "    ax.scatter(x2, y2, c='lime')\n",
    "    ax.scatter(a1, b1, c='red', label='actual')\n",
    "    ax.scatter(a2, b2, c='red')\n",
    "    ax.legend()\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=range(len(predicted)), interval=30)\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
