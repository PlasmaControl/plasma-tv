{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from pathlib import Path\n",
    "from scipy.io import readsav\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(filename):\n",
    "    dat = readsav(filename)\n",
    "    emission = dat['emission_structure']\n",
    "    return emission[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['tv_raw.hdf5', 'tv_crop.hdf5', 'tv_process.hdf5']\n",
    "file_name = Path(file_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.file = h5py.File(file_path, 'r')\n",
    "        self.target = self.file['tv_images']\n",
    "        self.label = self.file['points']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target = np.array(self.target[idx])\n",
    "        label = np.array(self.label[idx])\n",
    "        return target, label\n",
    "    \n",
    "    def close(self):\n",
    "        self.file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TVDataset(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"dataset length = {len(test_dataset)}\")\n",
    "print(f'label = {test_dataset[0][1]}')\n",
    "im_ratio = test_dataset[0][0].shape[1]/test_dataset[0][0].shape[0]\n",
    "if file_name.name == 'tv_process.hdf5':\n",
    "    plt.imshow(test_dataset[0][0], vmin=0, vmax=1, cmap = 'plasma')\n",
    "else:\n",
    "    plt.imshow(test_dataset[0][0], vmin=0, vmax=255, cmap = 'plasma')\n",
    "plt.colorbar(orientation=\"horizontal\",fraction=0.047*im_ratio)\n",
    "plt.title(\"target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mean = np.mean(test_dataset[:][0])\n",
    "target_std = np.std(test_dataset[:][0])\n",
    "label_mean = np.mean(test_dataset[:][1],axis=0)\n",
    "label_std = np.std(test_dataset[:][1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_mean, label_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data = transforms.Compose([\n",
    "    transforms.Normalize(mean=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 60 * 180, 128)\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)  # Add sigmoid activation to the final layer\n",
    "        return x\n",
    "    \n",
    "model = ConvNeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "model.train()\n",
    "scaler = GradScaler()  # for mixed precision training\n",
    "n_mini = len(dataloader)\n",
    "accumulation_steps = 10  # change this to fit your GPU memory\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()  # reset gradients at the start of each epoch\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        with autocast():  # for mixed precision training\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (i+1) % accumulation_steps == 0:  # perform an optimizer step every accumulation_steps mini-batches\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataloader with the sample dataset\n",
    "sample_dataset = TVDataset(target_path, label_path)\n",
    "sample_dataloader = DataLoader(sample_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "# set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# initialize the loss and accuracy\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# iterate over the sample dataloader\n",
    "with torch.no_grad():\n",
    "    for data in sample_dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        outputs = model(inputs)\n",
    "        print(outputs)\n",
    "        print(labels)\n",
    "        test_loss += loss_fn(outputs, labels).item()\n",
    "        print(test_loss)\n",
    "        total += labels.size(0)\n",
    "        break\n",
    "\n",
    "# calculate the loss and accuracy\n",
    "test_loss /= len(sample_dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TVDataset(target_path, label_path)\n",
    "# print(f'label = {test_dataset[0][1]}')\n",
    "tensor_test = test_dataset[0][0].unsqueeze(0)\n",
    "predicted = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_dataset))):\n",
    "        data = test_dataset[i][0].unsqueeze(0)\n",
    "        predicted.append(model(data.float().to(device)).cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute data\n",
    "data = [(predicted[num], test_dataset[num][1].numpy()) for num in tqdm(range(len(predicted)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "# Create scatter plots\n",
    "scat_pred = ax.scatter([], [], c='lime', label='predicted')\n",
    "scat_actual = ax.scatter([], [], c='red', label='actual')\n",
    "\n",
    "def update(num):\n",
    "    pred, actual = data[num]\n",
    "    x1, y1, x2, y2 = pred\n",
    "    a1, b1, a2, b2 = actual\n",
    "    scat_pred.set_offsets(np.c_[[x1, x2], [y1, y2]])\n",
    "    scat_actual.set_offsets(np.c_[[a1, a2], [b1, b2]])\n",
    "    return scat_pred, scat_actual\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=tqdm(range(len(predicted))), interval=30)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create scatter plots\n",
    "scat_pred = ax.scatter([], [], c='lime', label='predicted')\n",
    "scat_actual = ax.scatter([], [], c='red', label='actual')\n",
    "\n",
    "def update(num):\n",
    "    pred, actual = data[num]\n",
    "    x1, y1, x2, y2 = pred\n",
    "    a1, b1, a2, b2 = actual\n",
    "    scat_pred.set_offsets(np.c_[[x1, x2], [y1, y2]])\n",
    "    scat_actual.set_offsets(np.c_[[a1, a2], [b1, b2]])\n",
    "    return scat_pred, scat_actual\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "pbar = tqdm(total=len(predicted))\n",
    "ani = animation.FuncAnimation(fig, update, frames=range(len(predicted)), interval=30, blit=True, repeat=False)\n",
    "\n",
    "def update_progress(current, total):\n",
    "    pbar.update()\n",
    "\n",
    "ani.save(Path('./tmp/animation.mp4'), writer='ffmpeg', fps=60, progress_callback=update_progress)\n",
    "pbar.close()\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
