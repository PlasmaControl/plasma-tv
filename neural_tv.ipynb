{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Methods for TangTV Point Prediction\n",
    "\n",
    "Methods are used for raw TV videos, inverted TV videos, and synthetic videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils.get_file import GetTV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TV Location Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('outputs/hdf5')\n",
    "file_name = 'tv_inv_outer.h5'\n",
    "\n",
    "with h5py.File(file_path / file_name, 'r') as f:\n",
    "    vid = f['vid'][:]\n",
    "    inverted = f['inverted'][:]\n",
    "    points = f['points'][:]\n",
    "    vid_only = f['vid_only'][:]\n",
    "\n",
    "tv = GetTV()\n",
    "files = tv.list_files()\n",
    "elevation = tv.load(files[0], 'elevation')[0]\n",
    "radii = tv.load(files[0], 'radii')[0]\n",
    "vid_shape = tv.load(files[0], 'vid')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 700\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(vid[idx])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(inverted[idx],origin='lower')\n",
    "plt.scatter(points[idx][:,0], points[idx][:,1], c='r', s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_2 = vid.reshape(len(vid), -1)\n",
    "points_2 = points.reshape(len(points), -1)\n",
    "X_train, X_test, y_train, y_test, _, inv_test = train_test_split(vid_2, points_2, inverted, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, inv_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression() # try ridge regression\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = regr.score(X_test, y_test)\n",
    "r_predict = regr.predict(X_test)\n",
    "real_predict = np.array([radii[np.round(r_predict[:,0]).astype(int)],elevation[np.round(r_predict[:,1]).astype(int)]]).T\n",
    "real_y = np.array([radii[np.round(y_test[:,0]).astype(int)],elevation[np.round(y_test[:,1]).astype(int)]]).T\n",
    "print(r_sq)\n",
    "print(f\"RMS (cm) : {np.sqrt(mean_squared_error(real_predict, real_y)*100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = Path('outputs/models')\n",
    "regr_dump = LinearRegression()\n",
    "regr_dump.fit(vid_2, points_2)\n",
    "model_filename = model_file_path / Path('lr_' + file_name).with_suffix('.pkl')\n",
    "pickle.dump(regr_dump, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reshape = X_test.reshape(len(X_test), vid_shape[0], vid_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_predict_full = regr.predict(vid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, bx) = plt.subplots(2,1)\n",
    "\n",
    "# Create scatter plots\n",
    "inv_plot = ax.imshow(inverted[0], origin='lower')\n",
    "scat_pred = ax.scatter([], [], c='lime', s = 5, label='predicted')\n",
    "scat_actual = ax.scatter([], [], c='red', s = 5, label='actual')\n",
    "vid_plot = bx.imshow(vid[0])\n",
    "# ax.set_xlim([1,2])\n",
    "# ax.set_ylim([-1.4,-.4])\n",
    "ax.legend()\n",
    "ax.set_title(\"Inverted View\")\n",
    "bx.set_title(\"rt-TangTV View\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "bx.set_xticks([])\n",
    "bx.set_yticks([])\n",
    "fig.suptitle(f\"{file_name} regression, score = {r_sq:.4f}\")\n",
    "plt.tight_layout()\n",
    "\n",
    "def update(num):\n",
    "    x, y = r_predict_full[num]\n",
    "    a, b = points_2[num]\n",
    "    inv_plot.set_data(inverted[num])\n",
    "    scat_pred.set_offsets((x, y))\n",
    "    scat_actual.set_offsets((a, b))\n",
    "    vid_plot.set_data(vid[num])\n",
    "    return inv_plot, scat_pred, scat_actual, vid_plot\n",
    "\n",
    "FFwriter = animation.FFMpegWriter(fps=60)\n",
    "ani = animation.FuncAnimation(fig, update, frames=tqdm(range(len(r_predict_full))), interval=20, blit=True)\n",
    "ani.save(Path(f'./tmp/{file_name}_regress_full.gif'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, bx) = plt.subplots(2,1)\n",
    "\n",
    "# Create scatter plots\n",
    "inv_plot = ax.imshow(inv_test[0], origin='lower')\n",
    "scat_pred = ax.scatter([], [], c='lime', label='predicted')\n",
    "scat_actual = ax.scatter([], [], c='red', label='actual')\n",
    "vid_plot = bx.imshow(X_test_reshape[0])\n",
    "# ax.set_xlim([1,2])\n",
    "# ax.set_ylim([-1.4,-.4])\n",
    "ax.legend()\n",
    "ax.set_title(\"Emission Front Locations\")\n",
    "bx.set_title(\"Inversion Image\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "bx.set_xticks([])\n",
    "bx.set_yticks([])\n",
    "fig.suptitle(f\"{file_name} regression, score = {r_sq:.4f}\")\n",
    "plt.tight_layout()\n",
    "\n",
    "def update(num):\n",
    "    x, y = r_predict[num]\n",
    "    a, b = y_test[num]\n",
    "    inv_plot.set_data(inv_test[num])\n",
    "    scat_pred.set_offsets((x, y))\n",
    "    scat_actual.set_offsets((a, b))\n",
    "    vid_plot.set_data(X_test_reshape[num])\n",
    "    return inv_plot, scat_pred, scat_actual, vid_plot\n",
    "\n",
    "FFwriter = animation.FFMpegWriter(fps=60)\n",
    "ani = animation.FuncAnimation(fig, update, frames=tqdm(range(len(r_predict))), interval=20, blit=True)\n",
    "ani.save(Path(f'./tmp/{file_name}_regress_full.mp4'), writer=FFwriter)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression for Shot by Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('outputs/hdf5')\n",
    "file_name = 'tv_inv_outer.h5'\n",
    "\n",
    "with h5py.File(file_path / file_name, 'r') as f:\n",
    "    vid_train = f['vid_train'][:]\n",
    "    inverted_train = f['inverted_train'][:]\n",
    "    points_train = f['points_train'][:]\n",
    "    vid_test = f['vid_test'][:]\n",
    "    inverted_test = f['inverted_test'][:]\n",
    "    points_test = f['points_test'][:]\n",
    "\n",
    "tv = GetTV()\n",
    "files = tv.list_files()\n",
    "elevation = tv.load(files[0], 'elevation')[0]\n",
    "radii = tv.load(files[0], 'radii')[0]\n",
    "vid_shape = tv.load(files[0], 'vid')[0].shape\n",
    "vid_train_reshape = vid_train.reshape(len(vid_train), -1)\n",
    "points_train_reshape = points_train.reshape(len(points_train), -1)\n",
    "vid_test_reshape = vid_test.reshape(len(vid_test), -1)\n",
    "points_test_reshape = points_test.reshape(len(points_test), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vid_train_reshape[1])\n",
    "print(vid_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression() # try ridge regression\n",
    "regr.fit(vid_train_reshape, points_train_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = regr.score(vid_test_reshape, points_test_reshape)\n",
    "r_predict = regr.predict(vid_test_reshape)\n",
    "real_predict = np.array([radii[np.round(r_predict[:,0]).astype(int)],elevation[np.round(r_predict[:,1]).astype(int)]]).T\n",
    "real_y = np.array([radii[np.round(points_test_reshape[:,0]).astype(int)],elevation[np.round(points_test_reshape[:,1]).astype(int)]]).T\n",
    "rms = np.sqrt(mean_squared_error(real_predict, real_y)*100)\n",
    "print(r_sq)\n",
    "print(f\"RMS (cm) : {rms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, bx) = plt.subplots(2,1)\n",
    "\n",
    "# Create scatter plots\n",
    "inv_plot = ax.imshow(inverted_test[0], origin='lower')\n",
    "scat_pred = ax.scatter([], [], c='lime', s = 5, label='predicted')\n",
    "scat_actual = ax.scatter([], [], c='red', s = 5, label='actual')\n",
    "vid_plot = bx.imshow(vid_test[0])\n",
    "# ax.set_xlim([1,2])\n",
    "# ax.set_ylim([-1.4,-.4])\n",
    "ax.legend()\n",
    "ax.set_title(\"Inverted View\")\n",
    "bx.set_title(\"rt-TangTV View\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "bx.set_xticks([])\n",
    "bx.set_yticks([])\n",
    "fig.suptitle(f\"{file_name} regression, RMS (cm) = {rms:.4f}\")\n",
    "plt.tight_layout()\n",
    "\n",
    "def update(num):\n",
    "    x, y = r_predict[num]\n",
    "    a, b = points_test_reshape[num]\n",
    "    inv_plot.set_data(inverted_test[num])\n",
    "    scat_pred.set_offsets((x, y))\n",
    "    scat_actual.set_offsets((a, b))\n",
    "    vid_plot.set_data(vid_test[num])\n",
    "    return inv_plot, scat_pred, scat_actual, vid_plot\n",
    "\n",
    "FFwriter = animation.FFMpegWriter(fps=60)\n",
    "ani = animation.FuncAnimation(fig, update, frames=tqdm(range(len(r_predict))), interval=20, blit=True)\n",
    "ani.save(Path(f'./tmp/{file_name}_regress_full.gif'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('.\\hdf5')\n",
    "file_names = ['tv_raw.hdf5', 'tv_crop.hdf5', 'tv_process.hdf5']\n",
    "file_name = file_path / file_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(file_name, 'r') as f:\n",
    "    target = f['tv_images'][:]\n",
    "    label = f['points'][:]\n",
    "\n",
    "target_norm = 127.5\n",
    "target_std = 255\n",
    "label_norm = np.mean(label,axis=0)\n",
    "label_std = np.std(label,axis=0)\n",
    "del target\n",
    "del label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"target_mean: {target_norm:.4f}\")\n",
    "print(f\"target_std: {target_std:.4f}\")\n",
    "print(f\"label_mean: {label_norm}\")\n",
    "print(f\"label_std: {label_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVDataset(Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.file_path = file_path\n",
    "        self.file = h5py.File(file_path, 'r')\n",
    "        self.target = self.file['tv_images'][:][:, np.newaxis, ...] / 255\n",
    "        self.label = self.file['points'][:]\n",
    "        self.transform = transform\n",
    "        self.file.close()\n",
    "        if transform:\n",
    "            self.target = transform(torch.from_numpy(self.target).float())\n",
    "            self.label = torch.from_numpy(self.label).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target = self.target[idx]\n",
    "        label = self.label[idx]\n",
    "        return target, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(8, 8)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(672 , 128)\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(256*256, 256)\n",
    "        self.fc2 = nn.Linear(256, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, n_epochs, device):\n",
    "    model.train()\n",
    "    loss_norm = len(dataloader.dataset)\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "        print(f'{epoch + 1} loss: {running_loss / loss_norm:.3}')\n",
    "\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = CustomTransform(target_norm, label_norm, target_std, label_std)\n",
    "transform = T.Resize(size = (256,256), antialias=True)\n",
    "test_dataset = TVDataset(file_name, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_dataset))\n",
    "train_num = int(len(test_dataset)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train, test = random_split(test_dataset, [train_num, len(test_dataset) - train_num])\n",
    "dataloader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"target datatype = {test_dataset[0][0].dtype}, label datatype = {test_dataset[0][1].dtype}\")\n",
    "print(f\"dataset length = {len(test_dataset)}\")\n",
    "print(f'label = {test_dataset[0][1]}')\n",
    "im_ratio = test_dataset[0][0][0].shape[1]/test_dataset[0][0][0].shape[0]\n",
    "plt.imshow(test_dataset[0][0][0], cmap = 'plasma')\n",
    "plt.colorbar(orientation=\"horizontal\",fraction=0.047*im_ratio)\n",
    "plt.title(\"target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP().to(device)\n",
    "# summary(model, input_size = (1, 250, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "n_epochs = 35\n",
    "\n",
    "model = train_model(model, dataloader, optimizer, criterion, n_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have loaded the new dataset into a variable named `new_dataset`\n",
    "# and created a dataloader for it named `new_dataloader`\n",
    "new_dataloader = DataLoader(test, batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=0)\n",
    "n_samples = len(new_dataloader.dataset)\n",
    "output_size = len(new_dataloader.dataset[0][1])\n",
    "predicted = np.zeros((n_samples, output_size))\n",
    "actual = np.zeros((n_samples, output_size))\n",
    "model.eval()\n",
    "\n",
    "# Iterate over the dataloader and predict the output for each input\n",
    "with torch.no_grad():\n",
    "    start_index = 0\n",
    "    for inputs, actual_outputs in new_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        predicted_outputs = model(inputs)\n",
    "        end_index = start_index + predicted_outputs.shape[0]\n",
    "        predicted[start_index:end_index] = predicted_outputs.cpu().numpy()\n",
    "        actual[start_index:end_index] = actual_outputs.numpy()\n",
    "        start_index = end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renorm_actual = new_dataloader.dataset[:][1].numpy()\n",
    "renorm_predicted = predicted\n",
    "\n",
    "print(renorm_actual)\n",
    "print(renorm_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMS (cm) : {np.sqrt(mean_squared_error(renorm_actual, renorm_predicted))*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create scatter plots\n",
    "scat_pred = ax.scatter([], [], c='lime', label='predicted')\n",
    "scat_actual = ax.scatter([], [], c='red', label='actual')\n",
    "ax.set_xlim([1,2])\n",
    "ax.set_ylim([-1.4,-.4])\n",
    "ax.legend()\n",
    "ax.set_title(f\"{file_name.stem} : {scores}\")\n",
    "\n",
    "def update(num):\n",
    "    x1, y1, x2, y2 = renorm_predicted[num]\n",
    "    a1, b1, a2, b2 = renorm_actual[num]\n",
    "    scat_pred.set_offsets(np.c_[[x1, x2], [y1, y2]])\n",
    "    scat_actual.set_offsets(np.c_[[a1, a2], [b1, b2]])\n",
    "    return scat_pred, scat_actual\n",
    "\n",
    "FFwriter = animation.FFMpegWriter(fps=60)\n",
    "ani = animation.FuncAnimation(fig, update, frames=tqdm(range(len(predicted))), interval=20, blit=True)\n",
    "ani.save(Path(f'./tmp/{file_name.stem}.mp4'), writer=FFwriter)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion Location Detection for Semi-Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('.\\outputs\\hdf5')\n",
    "model_file_path = Path('.\\models')\n",
    "file_names = ['tv_raw.hdf5', 's_outs_v3_limited.h5', 'inversion_manual.hdf5']\n",
    "file_name = file_path / file_names[2]\n",
    "\n",
    "tv = GetTV()\n",
    "files = tv.list_files()\n",
    "elevation = tv.load(files[0], 'elevation')[0]\n",
    "radii = tv.load(files[0], 'radii')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(file_name, 'r') as f:\n",
    "#     l_r, l_z, r_r, r_z = f['rz'][:].T\n",
    "#     l_a, r_a = f['intensity'][:].T\n",
    "    \n",
    "# manual inversion points\n",
    "with h5py.File(file_name, 'r') as f:\n",
    "    inverted = f['inverted'][:]\n",
    "    points = f['points'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(points))\n",
    "print(np.min(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inverted.shape)\n",
    "inv_dim = inverted.shape[1] * inverted.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 180\n",
    "plt.imshow(inverted[idx],origin='lower')\n",
    "plt.scatter(points[idx][0], points[idx][1], c='red')\n",
    "plt.show()\n",
    "image = inverted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = np.array([np.resize(image[i], (256, 256)) for i in range(len(image))])\n",
    "# image = np.array([cv2.resize(image[i], (256, 256)) for i in range(len(image))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_raw, y_train, y_test = train_test_split(image, points, test_size=0.2)\n",
    "X_train = X_train.reshape((len(X_train), -1))\n",
    "X_test = X_test_raw.reshape((len(X_test_raw), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression() # try ridge regression\n",
    "regr.fit(X_train, y_train)\n",
    "r_sq = regr.score(X_test, y_test)\n",
    "r_predict = regr.predict(X_test)\n",
    "print(r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMS (cm) : {np.sqrt(mean_squared_error(y_test, r_predict))*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = image.reshape((len(image), -1))\n",
    "print(image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_dump = LinearRegression()\n",
    "regr_dump.fit(image2, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = y_test[1]\n",
    "print(radii[int(a)], elevation[int(b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = model_file_path / Path('lr_' + file_name.stem).with_suffix('.pkl')\n",
    "pickle.dump(regr_dump, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = model_file_path / Path('lr_' + file_name.stem).with_suffix('.pkl')\n",
    "loaded_model = pickle.load(open(model_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, bx) = plt.subplots(2,1)\n",
    "\n",
    "# Create scatter plots\n",
    "scat_pred = ax.scatter([], [], c='lime', label='predicted')\n",
    "scat_actual = ax.scatter([], [], c='red', label='actual')\n",
    "tv_image_plot = bx.imshow(X_test_raw[0])\n",
    "scat_image = bx.scatter([], [], c='red', s=1)\n",
    "ax.set_xlim([1,2])\n",
    "ax.set_ylim([-1.4,-.4])\n",
    "ax.legend()\n",
    "ax.set_title(\"Emission Front Locations\")\n",
    "bx.set_title(\"Inversion Image\")\n",
    "fig.suptitle(f\"{file_name.stem} regression, score = {r_sq:.4f}\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# def update(num):\n",
    "#     x1, y1, x2, y2 = r_predict[num]\n",
    "#     a1, b1, a2, b2 = y_test[num]\n",
    "#     scat_pred.set_offsets(np.c_[[x1, x2], [y1, y2]])\n",
    "#     scat_actual.set_offsets(np.c_[[a1, a2], [b1, b2]])\n",
    "#     tv_image_plot.set_data(image[num])\n",
    "#     return scat_pred, scat_actual, tv_image_plot\n",
    "\n",
    "def update(num):\n",
    "    x1, y1 = r_predict[num]\n",
    "    a1, b1 = y_test[num]\n",
    "    scat_pred.set_offsets([radii[int(x1)], elevation[int(y1)]])\n",
    "    scat_actual.set_offsets([radii[int(a1)], elevation[int(b1)]])\n",
    "    tv_image_plot.set_data(X_test_raw[num])\n",
    "    scat_image.set_offsets([a1, b1])\n",
    "    return scat_pred, scat_actual, tv_image_plot\n",
    "\n",
    "FFwriter = animation.FFMpegWriter(fps=60)\n",
    "ani = animation.FuncAnimation(fig, update, frames=tqdm(range(len(r_predict))), interval=10, blit=True)\n",
    "ani.save(Path(f'./tmp/stuff/{file_name.stem}_regress.gif'), writer='Pillow')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_samples():\n",
    "    \n",
    "    # Make R0s, Z0s, A0s, M0s\n",
    "    nsp = 5\n",
    "\n",
    "    R0s = np.zeros((nsp, 2))\n",
    "    Z0s = np.zeros((nsp, 2))\n",
    "    # Make R0s, Z0s, A0s, M0s\n",
    "    R0s_S = np.repeat(np.repeat(np.repeat(np.linspace(1.4, 1.7, nsp), nsp), nsp), nsp)\n",
    "    Z0s_S = np.tile(np.repeat(np.repeat(np.linspace(-1.3, -1.2, nsp), nsp), nsp), nsp)\n",
    "\n",
    "    R0s_X = np.repeat(np.tile(np.tile(np.linspace(1.3, 1.6, nsp), nsp), nsp), nsp)\n",
    "    Z0s_X = np.tile(np.tile(np.tile(np.linspace(-1.2, -0.9, nsp), nsp), nsp), nsp)\n",
    "\n",
    "    R0s = np.array([R0s_S, R0s_X]).T\n",
    "    Z0s = np.array([Z0s_S, Z0s_X]).T\n",
    "    \n",
    "    return R0s, Z0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'outputs/hdf5/s_outs_v3_limited.h5'\n",
    "with h5py.File(file_name, 'r') as f:\n",
    "    print(list(f.keys()))\n",
    "    synthetic_images = f['image'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file_name_2 = 'outputs/hdf5/x_outer_radiation.hdf5'\n",
    "with h5py.File(file_name_2, 'r') as f:\n",
    "    print(list(f.keys()))\n",
    "    points = f['points'][:]\n",
    "    tv_images = f['tv_images'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: s_outs_v3_limited is x point and outer radiation point. points is l_r, l_z, r_r, r_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R0s, Z0s = _make_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(synthetic_images.shape)\n",
    "print(tv_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1000\n",
    "# TV Images\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(cv2.flip(tv_images[idx],0), origin='lower')\n",
    "plt.colorbar(orientation='horizontal', ax=plt.gca())\n",
    "plt.title('TV Images')\n",
    "\n",
    "# Synthetic Images\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(synthetic_images[idx], origin='lower')\n",
    "plt.colorbar(orientation='horizontal', ax=plt.gca())\n",
    "plt.title('Synthetic Images')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = np.array([np.resize(synthetic_images[i], (256, 256)) for i in range(len(synthetic_images))])\n",
    "image2 = image2.reshape((len(image2), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = np.array([np.resize(cv2.flip(tv_images[i],0), (256, 256)) for i in range(len(tv_images))])\n",
    "image3 = image3.reshape((len(image3), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _, X_train_discard, X_test, y_train, y_test = train_test_split(image2, image3, points, test_size=0.2)\n",
    "\n",
    "y_train = y_train[:,[2,3]] / 201\n",
    "y_test = y_test[:,[2,3]] / 201\n",
    "# X_train = X_train / X_train.max() * 0.92\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = Ridge() # try ridge regression\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = regr.score(X_test, y_test)\n",
    "r_predict = regr.predict(X_test)\n",
    "print(f\"RMS (cm) : {np.sqrt(mean_squared_error(y_test, r_predict))*100}\")\n",
    "print(f\"R2_Score : {r_sq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[60])\n",
    "print(r_predict[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test[0,0], y_test[0,1], c='lime', label='actual')\n",
    "plt.scatter(r_predict[0,0], r_predict[0,1], c='red', label='predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 ms\n",
    "1. RZA database\n",
    "2. Error Linear, Normal Regression, and Ridge Regression\n",
    "3. Test thing on synthetic\n",
    "\n",
    "Delta Z * gain = target voltage (with constant scaling factor tune during experiment). D2, N2 gas puff\n",
    "\n",
    "V1, V2, V3, V4 (how far away from wall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
